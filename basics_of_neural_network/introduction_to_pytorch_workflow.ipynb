{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNI48+K3WTzjMFY8FNt6Afy",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "fb3eaf8bd6504ad799996cd2952dd023": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_964c5346229247009b234e1f44a1ad4c",
              "IPY_MODEL_85137d8da5604aeb9f943d2c0e79088f",
              "IPY_MODEL_ca4b22ba5ba4459ca7ad655bfea18413"
            ],
            "layout": "IPY_MODEL_96b265e8747940e3a65c4e8f6c7bb47e"
          }
        },
        "964c5346229247009b234e1f44a1ad4c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_01dec208d5114ebd915a13699c068d2e",
            "placeholder": "​",
            "style": "IPY_MODEL_6de097f40d1f45ecb62e24fe076b5390",
            "value": "Epochs: 100%"
          }
        },
        "85137d8da5604aeb9f943d2c0e79088f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7a1e9469cb2c437aa4014c4fdd48c475",
            "max": 30,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ecb908fdaf284cb88300d7d7a9a47982",
            "value": 30
          }
        },
        "ca4b22ba5ba4459ca7ad655bfea18413": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9a09c1cc6f9d416795ef957fa1182ac1",
            "placeholder": "​",
            "style": "IPY_MODEL_1a13ea8bb4e94241ab5e45132450e6e0",
            "value": " 30/30 [00:00&lt;00:00, 50.78it/s]"
          }
        },
        "96b265e8747940e3a65c4e8f6c7bb47e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "01dec208d5114ebd915a13699c068d2e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6de097f40d1f45ecb62e24fe076b5390": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7a1e9469cb2c437aa4014c4fdd48c475": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ecb908fdaf284cb88300d7d7a9a47982": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9a09c1cc6f9d416795ef957fa1182ac1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1a13ea8bb4e94241ab5e45132450e6e0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ronald-hk-chung/ssnotebook/blob/main/basics_of_neural_network/introduction_to_pytorch_workflow.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Introduction to PyTorch Workflow\n",
        "\n",
        "Mission Statement:\n",
        "\n",
        "1. Usage of Dataset and DataLoader for model training\n",
        "2. Building `Learner` class for typical train/valid loop for model training\n",
        "3. Using `SSTLearner` class from `sstorch` package for training loop boilerplate\n"
      ],
      "metadata": {
        "id": "6ivfsXSYrps0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## PyTorch Workflow Steps\n",
        "\n",
        "Training pipline should be divided into 3 steps:\n",
        "\n",
        "1. Data Preparation\n",
        "2. Model Configuration\n",
        "3. Model Training\n",
        "\n",
        "A typical PyTorch Model Training will look like below:\n",
        "\n",
        "```python\n",
        "for X, y in DataLoader:\n",
        "    y_pred = model(x)\n",
        "    loss = loss_func(y_pred, y)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    optimizer.zero_grad()\n",
        "```\n",
        "\n",
        "As we start to build up on our analysis, global training loop can get messy very quickly. This notebook focus on the simplifing Model Training Step. We will built up the `sstorch` main learner package which supports typical PyTorch Model Training workflow\n",
        "\n",
        "GitHub Repo: https://github.com/ronald-hk-chung/sstorch\n",
        "\n",
        "The aim is to build a Model Training class `SSTLearner` encapsulating the basic train/valid loop for deep-learning in PyTorch, we can ensure code organisation which is important for further studies. Note that `SSTLearner` class has other added function including `LRFinder` and other `Callback` that can be customized and added to the typical training/valid loop process.\n",
        "\n",
        "For full documentation: https://ronald-hk-chung.github.io/sstorch/\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "dlPiKTEnSvFC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Synthetic Data from Linear Regression\n",
        "\n",
        "$y = w \\times X + b + noise$\n"
      ],
      "metadata": {
        "id": "LjZGuIgJdlE4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# To ensure reproducibility\n",
        "torch.manual_seed(42)\n",
        "\n",
        "# Generating synthetic data\n",
        "X = torch.rand(100, 1) # random numbers from a uniform distribution on the interval (0, 1)\n",
        "w_true, b_true = 0.5, 1\n",
        "noise = torch.randn(100, 1) * 0.03\n",
        "y = w_true * X + b_true + noise\n",
        "\n",
        "# Plot synthetic data\n",
        "fig, ax = plt.subplots(1, 1, sharey=True, figsize=(5,5))\n",
        "ax.scatter(X, y, color=\"b\")\n",
        "ax.set_title(\"Synthetic Training Data\");"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 468
        },
        "id": "MaUuhqJ8dvWL",
        "outputId": "c1409f7e-cda8-4b23-a9eb-2650b0fc4744"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 500x500 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Splitting into train/valid data\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.2)"
      ],
      "metadata": {
        "id": "yXhZAesJ-Jhn"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dataset\n",
        "\n",
        "Full Reference: https://pytorch.org/docs/stable/data.html\n",
        "\n",
        "In PyTorch, a **dataset** is represented by a regular Python class that inherits from the `Dataset` class\n",
        "\n",
        "The most fundamental methods it needs to impliemnt are\n",
        "\n",
        "*   `__init__(self)`: The constructor method takes the argument needed to build a list of tuples. Note that there is no need to load the whole dataset in the construtor method. If the dataset is large, loading it all at one would not be memory efficient. It is recommeded to load them on demand (whenever `__getitem__()` is called. It's typically used to store some essential locations like file paths and image transforms.\n",
        "\n",
        "*   `__getitem__(self, idx)`: This method allow the dataset to be indexed so that it can work like a list **(dataset[idx])**. This should return a single data sample from athe dataset at a given index. The `__getitem__` method is where the actual dataloading and the preprocessing takes place. It takes an index as input and returns a data point, whcih can be a tensor or a ditionary of tensors. This method is used by `DataLoader` class to load and preprocess the data.\n",
        "\n",
        "* `__len__(self)`: This shoudl return the size of the whole dataset. The indexing is limited to the actual size.\n",
        "\n",
        "Below shows the sameple of creating **Custom Dataset** for our simple Linear regression data.\n",
        "\n"
      ],
      "metadata": {
        "id": "9bZJrqkv5l13"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import Dataset\n",
        "\n",
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, X, y):\n",
        "        self.X = X\n",
        "        self.y = y\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.X)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.X[idx], self.y[idx]\n",
        "\n",
        "train_data = CustomDataset(X_train, y_train)\n",
        "valid_data = CustomDataset(X_valid, y_valid)"
      ],
      "metadata": {
        "id": "djVSLh1v1r6W"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_data[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ICiuUFgj21o0",
        "outputId": "6c710e97-ddab-4554-b4ef-17fa3df3d243"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(tensor([0.7104]), tensor([1.3346]))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## TensorDataset\n",
        "\n",
        "For our small Dataset, we can just simply use `TensorDataset` class to create a dataset."
      ],
      "metadata": {
        "id": "Th-2OBv0eI5o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import TensorDataset\n",
        "\n",
        "train_data = TensorDataset(X_train, y_train)\n",
        "valid_data = TensorDataset(X_valid, y_valid)\n",
        "print(train_data[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aACDFwtX2_zs",
        "outputId": "de427be5-5497-4860-87c5-6eae2aeaef0a"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(tensor([0.7104]), tensor([1.3346]))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## DataLoader\n",
        "\n",
        "While it is ok to use the whole training data for a small data set to perform **batch gradient descent**, computation and memory will become an issue for big dataset and **mini-batch gradient descent**.\n",
        "\n",
        "**DataLoader** class to let our **Dataset** behave like an iterator by desciding on the **mini-batch-size** and to **shuffle** our Dataset during our training.\n",
        "\n",
        "There are a few important parameters to note when setting up the DataLoader:\n",
        "\n",
        "*   `shuffle`\n",
        "\n",
        "    Note that for the majority of cases except Time Series problem, we shoudl set `shuffle=True` for our trainiing set to improve the performance of gradient descent. There is no need ot shuffle validation set given we are are not computing gradient with it.\n",
        "\n",
        "    It is also possible to use it together with a **sampler** to fetch mini-batches that compensate for imablanced classes\n",
        "\n",
        "*   `batch_size`\n",
        "\n",
        "    It is typical to use powers of 2 for mini-batch sizes, like 16, 32, 64 or 128. and 32 seems to be the choice for most people. The main consideration for `batch_size` is the GPU memory\n",
        "\n",
        "*   `drop_last`\n",
        "\n",
        "    set to True to drop the last incomplete batch, if the dataset size is not divisible by the batch size. If False and the size of dataset is not divisible by the batch size, then the last batch will be smaller. (default: False)\n",
        "\n",
        "*   `pin_memory`\n",
        "\n",
        "     If True, the data loader will copy Tensors into device/CUDA pinned memory before returning them. If your data elements are a custom type, or your collate_fn returns a batch that is a custom type, see the example below.\n",
        "\n",
        "*   `num_workers`\n",
        "\n",
        "    how many subprocesses to use for data loading. 0 means that the data will be loaded in the main process. (default: 0)\n"
      ],
      "metadata": {
        "id": "jlu9vLO43bfk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "train_dataloader = DataLoader(dataset=train_data,\n",
        "                              batch_size=16,\n",
        "                              shuffle=True)\n",
        "\n",
        "valid_dataloader = DataLoader(dataset=valid_data,\n",
        "                              batch_size=16,\n",
        "                              shuffle=False)"
      ],
      "metadata": {
        "id": "sh2kJgzq6SaU"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "below command can help to retreive a mini-batch"
      ],
      "metadata": {
        "id": "n1BlruT86lWJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "next(iter(train_dataloader))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f__xgbX46kyb",
        "outputId": "d0706baf-7fdd-4e1b-c757-713807d782a0"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[tensor([[0.9103],\n",
              "         [0.4913],\n",
              "         [0.2695],\n",
              "         [0.4414],\n",
              "         [0.8913],\n",
              "         [0.1165],\n",
              "         [0.7539],\n",
              "         [0.5936],\n",
              "         [0.2696],\n",
              "         [0.1088],\n",
              "         [0.0041],\n",
              "         [0.7936],\n",
              "         [0.0050],\n",
              "         [0.8317],\n",
              "         [0.2018],\n",
              "         [0.3068]]),\n",
              " tensor([[1.4431],\n",
              "         [1.2331],\n",
              "         [1.1449],\n",
              "         [1.1995],\n",
              "         [1.4098],\n",
              "         [1.0895],\n",
              "         [1.3850],\n",
              "         [1.2877],\n",
              "         [1.1657],\n",
              "         [1.1152],\n",
              "         [1.0253],\n",
              "         [1.3861],\n",
              "         [0.9805],\n",
              "         [1.4059],\n",
              "         [1.0916],\n",
              "         [1.1565]])]"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Defining the Model\n",
        "\n",
        "In PyTorch, a model is represented by a regular Python class that inherits from the `nn.Module` class. The `nn.Module` class serves as a blueprint for a specific component of your network where\n",
        "\n",
        "*   **Encapsulation**: Modules neatly package together the tranable parameters (weights and biases) of the model's layers. Note that Module can also cantain other Modules, allowing to build complex hierarchies.\n",
        "*   **Statefulness**: Modules remember their parameters and inernal state, essentailly sotring what they have learned during training.\n",
        "*   **Composability**: Like building blocks, Modules can be connected to form intricate neural networks.\n",
        "\n",
        "One of the most crucial aspects of a Module is its ability ot manage its parameters.\n",
        "\n",
        "1. **Parameter Registration**: When variables are defined within a Module's constructor `__init__` PyTorch function like `nn.Linear` are automatrically registered to the Module as parameters\n",
        "\n",
        "2. **Parameter Access**: Pytorch allow access to Module's parameters in several ways. `module.parameters()` return an iterator to access all parameters. `module.state_dict()` returns an `OrderedDict` containing all parameters and their values.\n",
        "\n",
        "3. **Optimization**: During training, PyTorch optimizer (like Adam, SGD) specifically iterate over the parameters registered within a Module, updating them to minimize the loss function.\n",
        "\n",
        "<br/>\n",
        "\n",
        "Each model inheriting an `nn.Module` class should have\n",
        "1. `__init__()` method to initialising the class variables\n",
        "2. `forward()` method for forward-passing the input tensor into output"
      ],
      "metadata": {
        "id": "j0RW6x6OS43_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**`__init__()` method in `nn.Module1`**"
      ],
      "metadata": {
        "id": "vU4CUvD2wray"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "class LinearRegression(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.b = nn.Parameter(torch.randn(1, requires_grad=True, dtype=torch.float))\n",
        "        self.w = nn.Parameter(torch.randn(1, requires_grad=True, dtype=torch.float))\n",
        "\n",
        "    def forward(self, X):\n",
        "        return self.w * X + self.b\n",
        "\n",
        "model = LinearRegression()\n",
        "model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rvWQZo5Hv8DU",
        "outputId": "5a3df5dc-4da1-4e01-9929-2c6fb7723afb"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LinearRegression()"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the `__init__()` method, 2 parameters b and w where defined using `nn.Parameter` class. When attribute are definied within our custom module, its flagged as a parameter that needs to be tracked. This is done by `nn.Module` class overloading the `__setattr__` method that is responsible for setting attributes.\n",
        "\n",
        "<br/>\n",
        "\n",
        "**To access the parameters**\n",
        "\n",
        "1. Using `parameters()` method that return an iterator to access all parameters\n",
        "\n",
        "Under the hood, `parameter()` method is implimented as:\n",
        "\n",
        "```python\n",
        "def parameter(self):\n",
        "    yield self.b\n",
        "    yield self.w\n",
        "```"
      ],
      "metadata": {
        "id": "6apC1H87v_fd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "list(model.parameters())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NX-XJniWwDTD",
        "outputId": "3ba21438-e4e7-433f-987e-465c85f88927"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Parameter containing:\n",
              " tensor([-0.5359], requires_grad=True),\n",
              " Parameter containing:\n",
              " tensor([0.3355], requires_grad=True)]"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. `module.state_dict()` returns an `OrderedDict` containing all parameters and their values. Note that only learnable parameters are included as its purpose is to keep track of parameters that are going to be updated by the optimizer."
      ],
      "metadata": {
        "id": "LxUvOVSMwJzL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.state_dict()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p6USWpJkwLXX",
        "outputId": "845f6d8d-8d87-44d8-d9d1-5b0e5aea7bac"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "OrderedDict([('b', tensor([-0.5359])), ('w', tensor([0.3355]))])"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**`forward()` vs. `__call__()` Method**\n",
        "\n",
        "The goal of the `forward()` is to encapsoluate the forward pass computation. Note that `forward()` is called in the `__call__` function. Under the hood, the `__call__` method performs some additional bookkeeping to ensure that the `hooks` are properly registered.\n",
        "\n",
        "`forward(x)` method should not be called directly. You should call the whole model itself, as in model(x) to perform a forward pass and output predictions."
      ],
      "metadata": {
        "id": "xmw89SFvwN4n"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Sending the model to GPU device\n",
        "\n",
        "GPU Acceleration: Modern deep learning heavily relies on GPUs (Graphics Processing Units), which excel at parallel computations. Tensors are ideally suited for GPU acceleration; their structure naturally aligns with how GPUs carry out mathematical operations.\n",
        "\n",
        "We need to make sure our model and the data are on the same device"
      ],
      "metadata": {
        "id": "8_03WxXrxUvN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check what GPU we are using\n",
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nOsjMnDpxW1u",
        "outputId": "65e807b1-90cb-4cfa-88c9-2661e3f20126"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tue Apr 30 13:44:39 2024       \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 535.104.05             Driver Version: 535.104.05   CUDA Version: 12.2     |\n",
            "|-----------------------------------------+----------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                      |               MIG M. |\n",
            "|=========================================+======================+======================|\n",
            "|   0  Tesla T4                       Off | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   46C    P0              28W /  70W |    121MiB / 15360MiB |      0%      Default |\n",
            "|                                         |                      |                  N/A |\n",
            "+-----------------------------------------+----------------------+----------------------+\n",
            "                                                                                         \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                            |\n",
            "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
            "|        ID   ID                                                             Usage      |\n",
            "|=======================================================================================|\n",
            "+---------------------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "# Send model and data to the same device\n",
        "model.to(device)\n",
        "X, y = X.to(device), y.to(device)"
      ],
      "metadata": {
        "id": "ng9wGuPexZ1W"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Optimizer for gradient descent\n",
        "\n",
        "There are many optimizers under `torch.optim`.\n",
        "\n",
        "For `torch.optim` reference: https://pytorch.org/docs/stable/optim.html#module-torch.optim\n",
        "\n",
        "`SGD` is the most basic of them and `Adam` is one of the most popular. Different optimizers use different mechanics for updating the parameters.\n",
        "\n",
        "PyTorch opimitzers (like **SGD** or **Adam**)\n",
        "\n",
        "`step()` method takes the parameters we want to update, the learning rate we want to use and performs the updates through its . This replaces the manual updating of parameters in the training loop.\n",
        "\n",
        "`zero_grad()` method zero out all gradients in the model after `backward()`\n",
        "\n",
        "Below shows the most basic optimizer implimentation:\n"
      ],
      "metadata": {
        "id": "12m3VwZ1UlUj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class BasicOptim:\n",
        "  def __init__(self, params, lr):\n",
        "    self.params = params\n",
        "\n",
        "  def step(self):\n",
        "    self.params.data -= self.lr * self.params.grad\n",
        "\n",
        "  def zero_grad(self):\n",
        "    self.params.grad = None\n",
        "\n",
        "basic_optimizer = BasicOptim(params=model.parameters(), lr=0.1)\n",
        "basic_optimizer"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wTD0s03DynUf",
        "outputId": "4aa2c6d6-fe63-42b4-826a-90c1e5284a8f"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<__main__.BasicOptim at 0x796377bdea70>"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "For better model training, we should use the pre-built optimizer from `torch.optim`, below shows an example of **SGD Optimizer**"
      ],
      "metadata": {
        "id": "TF4vmuth0bFt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "optimizer = optim.SGD(params=model.parameters(), lr=0.1)\n",
        "optimizer.state_dict()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KL2jvV14yv-6",
        "outputId": "5c4b9afb-a5a0-4651-8cf9-860b94556eb1"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'state': {},\n",
              " 'param_groups': [{'lr': 0.1,\n",
              "   'momentum': 0,\n",
              "   'dampening': 0,\n",
              "   'weight_decay': 0,\n",
              "   'nesterov': False,\n",
              "   'maximize': False,\n",
              "   'foreach': None,\n",
              "   'differentiable': False,\n",
              "   'params': [0, 1]}]}"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Note that optimizer itself also has a state_dict() which contains its internal state as well as hyper-parameters.\n",
        "\n"
      ],
      "metadata": {
        "id": "G3nS-lP3y1kz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Defining a Loss Function\n",
        "\n",
        "To tackle the loss computation. PyTorch has a variety of loss function to choose from under `torch.nn`\n",
        "\n",
        "Reference: https://pytorch.org/docs/stable/nn.html\n",
        "\n",
        "For our linear regression problem, we are using the mean squared error(MSE) as loss function - `nn.MSELoss()`\n",
        "\n",
        "for full reference on the `nn.MSELoss()` - https://pytorch.org/docs/stable/generated/torch.nn.MSELoss.html#torch.nn.MSELoss"
      ],
      "metadata": {
        "id": "wR-lsz55T6aW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define an MSE loss function\n",
        "loss_fn = nn.MSELoss(reduction='mean')\n",
        "loss_fn"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WSarsHTpT2mn",
        "outputId": "42508a65-c7d8-4cd1-dc19-c17155d25ef5"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MSELoss()"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Defining the main Learner class\n",
        "\n",
        "**The Constructor**\n",
        "\n",
        "The constructor defines the attributes/arguments that make up the class. For the basic model training, we need to define 4 arguments:\n",
        "*   model\n",
        "*   loss\n",
        "*   optimizer\n",
        "*   data\n",
        "\n",
        "While conceptually data is not part of the model, it is the input that we need ot use to train the model and should be included as an argument. We will initialised with None and add a method `set_loader` that can be used to supply the data (or even swap the dataset) at a later time.\n",
        "\n",
        "In the constructor, we also initialise below:\n",
        "*   **placeholders** for objects that are not available at the moment of creation\n",
        "*   **variables** that we may want to keep track\n",
        "\n",
        "\n",
        "**Train Method**\n",
        "\n",
        "In the `train()` method, we need to add the **epoch-loop** where we set the training to go through a specified number of epochs (an input to the method). Moreoer, we also added the saving of results under `results` dictionary inside the `Learner` class\n",
        "\n",
        "\n",
        "**Train loop and Valid Loop**\n",
        "\n",
        "Inside the `train()` method, we define both `_train_loop()` and `_valid_loop()` which are both protected method indicated by the \"_\" in front of the name. The main intention for the train loop is to perform gradient descent. Note that the batch data is set to GPU inside each **mini-batch-loop**.\n",
        "\n",
        "\n",
        "**Train Step and Valid Step**\n",
        "\n",
        "This is the actual **Step** taken the calculate the loss. The reason for seperating this **Step** out is to ensure flexibility for different models. Note that we can subclass `Learner` class to override the `train_step()` and `valid_step()` method for more complex **step**\n",
        "\n",
        "Below shows the main construction of our `Learner` Class"
      ],
      "metadata": {
        "id": "WdI6-uaH0-Qs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Learner:\n",
        "    def __init__(self, model, loss_fn, train_dataloader, valid_dataloader):\n",
        "        # define attributes for learner class including model, loss_fn, optimizer and train_dl\n",
        "        self.model = model\n",
        "        self.loss_fn = loss_fn\n",
        "        self.optimizer = self.configure_optimizer()\n",
        "        self.train_dataloader = train_dataloader\n",
        "        self.valid_dataloader = valid_dataloader\n",
        "\n",
        "        # Set attributes that are going to be computed internally\n",
        "        self.total_epochs = 0\n",
        "        self.batch = None\n",
        "        self.loss = None    # loss from train/valid step\n",
        "        self.train_loss = None  # intermediate aggregate/avg train_loss during _train_loop\n",
        "        self.valid_loss = None  # intermediate aggregate/avg valid_loss during _valid_loop\n",
        "        self.results = {\n",
        "            'train_loss': [],\n",
        "            'valid_loss': []\n",
        "        }\n",
        "        # Setting up device agnostic code\n",
        "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "        # send model to GPU if available\n",
        "        self.model.to(self.device)\n",
        "\n",
        "    def configure_optimizer(self):\n",
        "        return torch.optim.SGD(params=self.model.parameters(),\n",
        "                               lr=0.1)\n",
        "\n",
        "    def train(self, epochs):\n",
        "        # perform train on specified number of epochs\n",
        "        for epoch in range(epochs):\n",
        "            # increment total_epochs\n",
        "            self.total_epochs += 1\n",
        "            # perform train_loop and valid_loop\n",
        "            self._train_loop()\n",
        "            self._valid_loop()\n",
        "            self.results['train_loss'].append(self.train_loss)\n",
        "            self.results['valid_loss'].append(self.valid_loss)\n",
        "            print(f'Epoch: {epoch} | Train Loss: {self.train_loss:.3f} | Valid Loss: {self.valid_loss:.3f}')\n",
        "\n",
        "    def _train_loop(self):\n",
        "        # put model into train mode - default state of model\n",
        "        self.model.train()\n",
        "        # initialise train_loss to 0\n",
        "        self.train_loss = 0\n",
        "        # Perform the PyTorch train Loop with gradient descent\n",
        "        for batch_num, batch in enumerate(self.train_dataloader):\n",
        "            # Send batch to GPU if available\n",
        "            self.batch = [tensor.to(self.device) for tensor in batch]\n",
        "            # train_step to perform forward pass to return loss\n",
        "            self.loss = self.train_step()\n",
        "            # aggregate train_loss\n",
        "            self.train_loss += self.loss.item()\n",
        "            # gradient descent using optimizer\n",
        "            self.loss.backward()\n",
        "            self.optimizer.step()\n",
        "            self.optimizer.zero_grad()\n",
        "        # take the average by dividing the aggregate train_loss to batch_num\n",
        "        self.train_loss /= len(self.train_dataloader)\n",
        "\n",
        "    def _valid_loop(self):\n",
        "        # put model into eval mode\n",
        "        self.model.eval()\n",
        "        # initialise valid_loss to 0\n",
        "        self.valid_loss = 0\n",
        "        # use torch.inference_mode as a context manager\n",
        "        # turns off gradient tracking which is not needed for validation\n",
        "        with torch.inference_mode():\n",
        "            for batch_num, batch in enumerate(self.valid_dataloader):\n",
        "                # Send batch to GPU if available\n",
        "                self.batch = [tensor.to(self.device) for tensor in batch]\n",
        "                self.loss = self.valid_step()\n",
        "                self.valid_loss += self.loss.item()\n",
        "            self.valid_loss /= len(self.valid_dataloader)\n",
        "\n",
        "    def train_step(self):\n",
        "        X, y = self.batch\n",
        "        y_logits = self.model(X)\n",
        "        loss = self.loss_fn(y_logits, y)\n",
        "        return loss\n",
        "\n",
        "    def valid_step(self):\n",
        "        X, y = self.batch\n",
        "        y_logits = self.model(X)\n",
        "        loss = self.loss_fn(y_logits, y)\n",
        "        return loss\n"
      ],
      "metadata": {
        "id": "UtO3w2Pu3MvT"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Putting it all together with the Learner class"
      ],
      "metadata": {
        "id": "gGC0js37UK9Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "learner = Learner(model=LinearRegression(),\n",
        "                  loss_fn=nn.MSELoss(reduction='mean'),\n",
        "                  train_dataloader=train_dataloader,\n",
        "                  valid_dataloader=valid_dataloader)"
      ],
      "metadata": {
        "id": "91LmCfZPUOdF"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "learner.train(30)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uRIYg6naY7du",
        "outputId": "9ce16774-7c07-4c1e-ad60-48481964f95b"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0 | Train Loss: 0.426 | Valid Loss: 0.053\n",
            "Epoch: 1 | Train Loss: 0.023 | Valid Loss: 0.003\n",
            "Epoch: 2 | Train Loss: 0.002 | Valid Loss: 0.000\n",
            "Epoch: 3 | Train Loss: 0.001 | Valid Loss: 0.000\n",
            "Epoch: 4 | Train Loss: 0.001 | Valid Loss: 0.000\n",
            "Epoch: 5 | Train Loss: 0.001 | Valid Loss: 0.000\n",
            "Epoch: 6 | Train Loss: 0.001 | Valid Loss: 0.000\n",
            "Epoch: 7 | Train Loss: 0.001 | Valid Loss: 0.000\n",
            "Epoch: 8 | Train Loss: 0.001 | Valid Loss: 0.000\n",
            "Epoch: 9 | Train Loss: 0.001 | Valid Loss: 0.000\n",
            "Epoch: 10 | Train Loss: 0.001 | Valid Loss: 0.000\n",
            "Epoch: 11 | Train Loss: 0.001 | Valid Loss: 0.000\n",
            "Epoch: 12 | Train Loss: 0.001 | Valid Loss: 0.000\n",
            "Epoch: 13 | Train Loss: 0.001 | Valid Loss: 0.000\n",
            "Epoch: 14 | Train Loss: 0.001 | Valid Loss: 0.000\n",
            "Epoch: 15 | Train Loss: 0.001 | Valid Loss: 0.000\n",
            "Epoch: 16 | Train Loss: 0.001 | Valid Loss: 0.000\n",
            "Epoch: 17 | Train Loss: 0.001 | Valid Loss: 0.000\n",
            "Epoch: 18 | Train Loss: 0.001 | Valid Loss: 0.000\n",
            "Epoch: 19 | Train Loss: 0.001 | Valid Loss: 0.000\n",
            "Epoch: 20 | Train Loss: 0.001 | Valid Loss: 0.000\n",
            "Epoch: 21 | Train Loss: 0.001 | Valid Loss: 0.000\n",
            "Epoch: 22 | Train Loss: 0.001 | Valid Loss: 0.000\n",
            "Epoch: 23 | Train Loss: 0.001 | Valid Loss: 0.000\n",
            "Epoch: 24 | Train Loss: 0.001 | Valid Loss: 0.000\n",
            "Epoch: 25 | Train Loss: 0.001 | Valid Loss: 0.000\n",
            "Epoch: 26 | Train Loss: 0.001 | Valid Loss: 0.000\n",
            "Epoch: 27 | Train Loss: 0.001 | Valid Loss: 0.000\n",
            "Epoch: 28 | Train Loss: 0.001 | Valid Loss: 0.000\n",
            "Epoch: 29 | Train Loss: 0.001 | Valid Loss: 0.000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "learner.model.state_dict()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0f9uRPmXbQYv",
        "outputId": "e54f9404-af62-4024-e240-dda7f4e7d77a"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "OrderedDict([('b', tensor([1.0060], device='cuda:0')),\n",
              "             ('w', tensor([0.4871], device='cuda:0'))])"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Our model predict the correct parameters for `b` and `w`"
      ],
      "metadata": {
        "id": "ToAiZFbl09ly"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Nested Models under nn.Module\n",
        "\n",
        "We can use PyTorch model as an attribute to our own model to created a nested model.\n",
        "\n",
        "For example, we can use `nn.Linear` to define a single-feature linear regression within our own model"
      ],
      "metadata": {
        "id": "kNBhu9wH1x1Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class NestedLinearRegression(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        # weight as w, bias as b\n",
        "        self.linear = nn.Linear(in_features=1, out_features=1, bias=True)\n",
        "    def forward(self, X):\n",
        "        return self.linear(X)\n",
        "\n",
        "learner = Learner(model=NestedLinearRegression(),\n",
        "                  loss_fn=nn.MSELoss(reduction='mean'),\n",
        "                  train_dataloader=train_dataloader,\n",
        "                  valid_dataloader=valid_dataloader)\n",
        "\n",
        "learner.train(30)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w-7wvtjX1gtm",
        "outputId": "392b1dcb-7eac-436c-f9f3-471efcb83bfa"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0 | Train Loss: 0.661 | Valid Loss: 0.092\n",
            "Epoch: 1 | Train Loss: 0.049 | Valid Loss: 0.014\n",
            "Epoch: 2 | Train Loss: 0.017 | Valid Loss: 0.009\n",
            "Epoch: 3 | Train Loss: 0.014 | Valid Loss: 0.008\n",
            "Epoch: 4 | Train Loss: 0.012 | Valid Loss: 0.006\n",
            "Epoch: 5 | Train Loss: 0.011 | Valid Loss: 0.006\n",
            "Epoch: 6 | Train Loss: 0.009 | Valid Loss: 0.005\n",
            "Epoch: 7 | Train Loss: 0.008 | Valid Loss: 0.004\n",
            "Epoch: 8 | Train Loss: 0.007 | Valid Loss: 0.004\n",
            "Epoch: 9 | Train Loss: 0.006 | Valid Loss: 0.003\n",
            "Epoch: 10 | Train Loss: 0.006 | Valid Loss: 0.003\n",
            "Epoch: 11 | Train Loss: 0.005 | Valid Loss: 0.002\n",
            "Epoch: 12 | Train Loss: 0.004 | Valid Loss: 0.002\n",
            "Epoch: 13 | Train Loss: 0.004 | Valid Loss: 0.002\n",
            "Epoch: 14 | Train Loss: 0.004 | Valid Loss: 0.001\n",
            "Epoch: 15 | Train Loss: 0.003 | Valid Loss: 0.001\n",
            "Epoch: 16 | Train Loss: 0.003 | Valid Loss: 0.001\n",
            "Epoch: 17 | Train Loss: 0.003 | Valid Loss: 0.001\n",
            "Epoch: 18 | Train Loss: 0.002 | Valid Loss: 0.001\n",
            "Epoch: 19 | Train Loss: 0.002 | Valid Loss: 0.001\n",
            "Epoch: 20 | Train Loss: 0.002 | Valid Loss: 0.001\n",
            "Epoch: 21 | Train Loss: 0.002 | Valid Loss: 0.001\n",
            "Epoch: 22 | Train Loss: 0.002 | Valid Loss: 0.001\n",
            "Epoch: 23 | Train Loss: 0.001 | Valid Loss: 0.000\n",
            "Epoch: 24 | Train Loss: 0.001 | Valid Loss: 0.000\n",
            "Epoch: 25 | Train Loss: 0.001 | Valid Loss: 0.000\n",
            "Epoch: 26 | Train Loss: 0.001 | Valid Loss: 0.000\n",
            "Epoch: 27 | Train Loss: 0.001 | Valid Loss: 0.000\n",
            "Epoch: 28 | Train Loss: 0.001 | Valid Loss: 0.000\n",
            "Epoch: 29 | Train Loss: 0.001 | Valid Loss: 0.000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "learner.model.state_dict()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r7kd5xK11s80",
        "outputId": "dc7801d3-e060-4bc7-8631-1a3ce1c51654"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "OrderedDict([('linear.weight', tensor([[0.4311]], device='cuda:0')),\n",
              "             ('linear.bias', tensor([1.0360], device='cuda:0'))])"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Sequential Models\n",
        "\n",
        "For straightforward models that use a series of built-in PyTorch Models (e.g. `nn.Linear`), where the output of one is sequentially fed as an input to the next, we can use `nn.Sequential` model.\n",
        "\n",
        "Note that `nn.Sequential` is a subclass of `nn.Module` with the objective to quickly impliemnt sequential modules without the requirement of the forward definition"
      ],
      "metadata": {
        "id": "5YF7rYcM1ewg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "learner = Learner(model=nn.Sequential(nn.Linear(1, 1)),\n",
        "                  loss_fn=nn.MSELoss(reduction='mean'),\n",
        "                  train_dataloader=train_dataloader,\n",
        "                  valid_dataloader=valid_dataloader)\n",
        "\n",
        "learner.train(30)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fZKopR5m2FMZ",
        "outputId": "93aeec49-b6c7-4cba-b094-020e486598f4"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0 | Train Loss: 2.236 | Valid Loss: 0.287\n",
            "Epoch: 1 | Train Loss: 0.125 | Valid Loss: 0.020\n",
            "Epoch: 2 | Train Loss: 0.013 | Valid Loss: 0.004\n",
            "Epoch: 3 | Train Loss: 0.007 | Valid Loss: 0.003\n",
            "Epoch: 4 | Train Loss: 0.006 | Valid Loss: 0.003\n",
            "Epoch: 5 | Train Loss: 0.005 | Valid Loss: 0.002\n",
            "Epoch: 6 | Train Loss: 0.004 | Valid Loss: 0.002\n",
            "Epoch: 7 | Train Loss: 0.004 | Valid Loss: 0.002\n",
            "Epoch: 8 | Train Loss: 0.004 | Valid Loss: 0.001\n",
            "Epoch: 9 | Train Loss: 0.003 | Valid Loss: 0.001\n",
            "Epoch: 10 | Train Loss: 0.003 | Valid Loss: 0.001\n",
            "Epoch: 11 | Train Loss: 0.003 | Valid Loss: 0.001\n",
            "Epoch: 12 | Train Loss: 0.002 | Valid Loss: 0.001\n",
            "Epoch: 13 | Train Loss: 0.002 | Valid Loss: 0.001\n",
            "Epoch: 14 | Train Loss: 0.002 | Valid Loss: 0.001\n",
            "Epoch: 15 | Train Loss: 0.002 | Valid Loss: 0.001\n",
            "Epoch: 16 | Train Loss: 0.002 | Valid Loss: 0.001\n",
            "Epoch: 17 | Train Loss: 0.001 | Valid Loss: 0.000\n",
            "Epoch: 18 | Train Loss: 0.001 | Valid Loss: 0.000\n",
            "Epoch: 19 | Train Loss: 0.001 | Valid Loss: 0.000\n",
            "Epoch: 20 | Train Loss: 0.001 | Valid Loss: 0.000\n",
            "Epoch: 21 | Train Loss: 0.001 | Valid Loss: 0.000\n",
            "Epoch: 22 | Train Loss: 0.001 | Valid Loss: 0.000\n",
            "Epoch: 23 | Train Loss: 0.001 | Valid Loss: 0.000\n",
            "Epoch: 24 | Train Loss: 0.001 | Valid Loss: 0.000\n",
            "Epoch: 25 | Train Loss: 0.001 | Valid Loss: 0.000\n",
            "Epoch: 26 | Train Loss: 0.001 | Valid Loss: 0.000\n",
            "Epoch: 27 | Train Loss: 0.001 | Valid Loss: 0.000\n",
            "Epoch: 28 | Train Loss: 0.001 | Valid Loss: 0.000\n",
            "Epoch: 29 | Train Loss: 0.001 | Valid Loss: 0.000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "learner.model.state_dict()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6qETievb2UcV",
        "outputId": "5d1447e0-f0eb-4e4b-8ac5-9352568d6e70"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "OrderedDict([('0.weight', tensor([[0.4515]], device='cuda:0')),\n",
              "             ('0.bias', tensor([1.0251], device='cuda:0'))])"
            ]
          },
          "metadata": {},
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Installing sstorch package through pip\n",
        "\n",
        "We will use `sstorch` package to continue our development for minimizing the boilerplate code for PyTorch Code. Note that `sstorch` also has other functions that is useful for PyTorch training that will be documented under sstorch reference session in the ssnote"
      ],
      "metadata": {
        "id": "3IGAF9JOWAmU"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Om1eSKiSSuay",
        "outputId": "ad19114b-d0da-4163-8561-3f2816b062c5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m65.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m141.1/141.1 kB\u001b[0m \u001b[31m16.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for sstorch (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "# Installing sstorch package\n",
        "!pip -q install git+https://github.com/ronald-hk-chung/sstorch.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sstorch.learner import SSTLearner\n",
        "\n",
        "model = LinearRegression()\n",
        "optimizer = torch.optim.SGD(params=model.parameters(), lr=0.1)\n",
        "loss_fn = nn.MSELoss()\n",
        "\n",
        "sstlearner = SSTLearner(model=model,\n",
        "                        loss_fn=loss_fn,\n",
        "                        optimizer=optimizer,\n",
        "                        train_dataloader=train_dataloader,\n",
        "                        valid_dataloader=valid_dataloader)"
      ],
      "metadata": {
        "id": "vMzf1jG4cNcm"
      },
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sstlearner.train(30)"
      ],
      "metadata": {
        "id": "02r5RNzxQh-h",
        "outputId": "4209326b-6397-4d69-fa08-9f7775ea7a2a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "fb3eaf8bd6504ad799996cd2952dd023",
            "964c5346229247009b234e1f44a1ad4c",
            "85137d8da5604aeb9f943d2c0e79088f",
            "ca4b22ba5ba4459ca7ad655bfea18413",
            "96b265e8747940e3a65c4e8f6c7bb47e",
            "01dec208d5114ebd915a13699c068d2e",
            "6de097f40d1f45ecb62e24fe076b5390",
            "7a1e9469cb2c437aa4014c4fdd48c475",
            "ecb908fdaf284cb88300d7d7a9a47982",
            "9a09c1cc6f9d416795ef957fa1182ac1",
            "1a13ea8bb4e94241ab5e45132450e6e0"
          ]
        }
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Epochs:   0%|          | 0/30 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "fb3eaf8bd6504ad799996cd2952dd023"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\rTrain Step 1/5 | Loss(Cur/Avg): 3.891 / 3.891 | Metric(Cur/Avg): 0 / 0.0\rTrain Step 2/5 | Loss(Cur/Avg): 1.923 / 2.907 | Metric(Cur/Avg): 0 / 0.0\rTrain Step 3/5 | Loss(Cur/Avg): 1.189 / 2.334 | Metric(Cur/Avg): 0 / 0.0\rTrain Step 4/5 | Loss(Cur/Avg): 0.777 / 1.945 | Metric(Cur/Avg): 0 / 0.0\rTrain Step 5/5 | Loss(Cur/Avg): 0.518 / 1.66 | Metric(Cur/Avg): 0 / 0.0\rValid Step 1/2 | Loss(Cur/Avg): 0.276 / 0.276 | Metric(Cur/Avg): 0 / 0.0\rValid Step 2/2 | Loss(Cur/Avg): 0.239 / 0.258 | Metric(Cur/Avg): 0 / 0.0\rEpoch: 1 | LR: 1.0E-01 | train_loss: 1.66 | valid_loss: 0.258 \n",
            "----------------------------------------------------------------------------------------------------\n",
            "\rTrain Step 1/5 | Loss(Cur/Avg): 0.273 / 0.273 | Metric(Cur/Avg): 0 / 0.0\rTrain Step 2/5 | Loss(Cur/Avg): 0.154 / 0.213 | Metric(Cur/Avg): 0 / 0.0\rTrain Step 3/5 | Loss(Cur/Avg): 0.128 / 0.185 | Metric(Cur/Avg): 0 / 0.0\rTrain Step 4/5 | Loss(Cur/Avg): 0.124 / 0.17 | Metric(Cur/Avg): 0 / 0.0\rTrain Step 5/5 | Loss(Cur/Avg): 0.085 / 0.153 | Metric(Cur/Avg): 0 / 0.0\rValid Step 1/2 | Loss(Cur/Avg): 0.071 / 0.071 | Metric(Cur/Avg): 0 / 0.0\rValid Step 2/2 | Loss(Cur/Avg): 0.045 / 0.058 | Metric(Cur/Avg): 0 / 0.0\rEpoch: 2 | LR: 1.0E-01 | train_loss: 0.153 | valid_loss: 0.058 \n",
            "----------------------------------------------------------------------------------------------------\n",
            "\rTrain Step 1/5 | Loss(Cur/Avg): 0.093 / 0.093 | Metric(Cur/Avg): 0 / 0.0\rTrain Step 2/5 | Loss(Cur/Avg): 0.073 / 0.083 | Metric(Cur/Avg): 0 / 0.0\rTrain Step 3/5 | Loss(Cur/Avg): 0.062 / 0.076 | Metric(Cur/Avg): 0 / 0.0\rTrain Step 4/5 | Loss(Cur/Avg): 0.069 / 0.074 | Metric(Cur/Avg): 0 / 0.0\rTrain Step 5/5 | Loss(Cur/Avg): 0.052 / 0.07 | Metric(Cur/Avg): 0 / 0.0\rValid Step 1/2 | Loss(Cur/Avg): 0.052 / 0.052 | Metric(Cur/Avg): 0 / 0.0\rValid Step 2/2 | Loss(Cur/Avg): 0.031 / 0.041 | Metric(Cur/Avg): 0 / 0.0\rEpoch: 3 | LR: 1.0E-01 | train_loss: 0.07 | valid_loss: 0.041 \n",
            "----------------------------------------------------------------------------------------------------\n",
            "\rTrain Step 1/5 | Loss(Cur/Avg): 0.051 / 0.051 | Metric(Cur/Avg): 0 / 0.0\rTrain Step 2/5 | Loss(Cur/Avg): 0.068 / 0.059 | Metric(Cur/Avg): 0 / 0.0\rTrain Step 3/5 | Loss(Cur/Avg): 0.053 / 0.057 | Metric(Cur/Avg): 0 / 0.0\rTrain Step 4/5 | Loss(Cur/Avg): 0.065 / 0.059 | Metric(Cur/Avg): 0 / 0.0\rTrain Step 5/5 | Loss(Cur/Avg): 0.048 / 0.057 | Metric(Cur/Avg): 0 / 0.0\rValid Step 1/2 | Loss(Cur/Avg): 0.044 / 0.044 | Metric(Cur/Avg): 0 / 0.0\rValid Step 2/2 | Loss(Cur/Avg): 0.026 / 0.035 | Metric(Cur/Avg): 0 / 0.0\rEpoch: 4 | LR: 1.0E-01 | train_loss: 0.057 | valid_loss: 0.035 \n",
            "----------------------------------------------------------------------------------------------------\n",
            "\rTrain Step 1/5 | Loss(Cur/Avg): 0.051 / 0.051 | Metric(Cur/Avg): 0 / 0.0\rTrain Step 2/5 | Loss(Cur/Avg): 0.061 / 0.056 | Metric(Cur/Avg): 0 / 0.0\rTrain Step 3/5 | Loss(Cur/Avg): 0.037 / 0.05 | Metric(Cur/Avg): 0 / 0.0\rTrain Step 4/5 | Loss(Cur/Avg): 0.039 / 0.047 | Metric(Cur/Avg): 0 / 0.0\rTrain Step 5/5 | Loss(Cur/Avg): 0.063 / 0.05 | Metric(Cur/Avg): 0 / 0.0\rValid Step 1/2 | Loss(Cur/Avg): 0.039 / 0.039 | Metric(Cur/Avg): 0 / 0.0\rValid Step 2/2 | Loss(Cur/Avg): 0.022 / 0.031 | Metric(Cur/Avg): 0 / 0.0\rEpoch: 5 | LR: 1.0E-01 | train_loss: 0.05 | valid_loss: 0.031 \n",
            "----------------------------------------------------------------------------------------------------\n",
            "\rTrain Step 1/5 | Loss(Cur/Avg): 0.046 / 0.046 | Metric(Cur/Avg): 0 / 0.0\rTrain Step 2/5 | Loss(Cur/Avg): 0.045 / 0.045 | Metric(Cur/Avg): 0 / 0.0\rTrain Step 3/5 | Loss(Cur/Avg): 0.053 / 0.048 | Metric(Cur/Avg): 0 / 0.0\rTrain Step 4/5 | Loss(Cur/Avg): 0.045 / 0.047 | Metric(Cur/Avg): 0 / 0.0\rTrain Step 5/5 | Loss(Cur/Avg): 0.031 / 0.044 | Metric(Cur/Avg): 0 / 0.0\rValid Step 1/2 | Loss(Cur/Avg): 0.033 / 0.033 | Metric(Cur/Avg): 0 / 0.0\rValid Step 2/2 | Loss(Cur/Avg): 0.019 / 0.026 | Metric(Cur/Avg): 0 / 0.0\rEpoch: 6 | LR: 1.0E-01 | train_loss: 0.044 | valid_loss: 0.026 \n",
            "----------------------------------------------------------------------------------------------------\n",
            "\rTrain Step 1/5 | Loss(Cur/Avg): 0.032 / 0.032 | Metric(Cur/Avg): 0 / 0.0\rTrain Step 2/5 | Loss(Cur/Avg): 0.037 / 0.034 | Metric(Cur/Avg): 0 / 0.0\rTrain Step 3/5 | Loss(Cur/Avg): 0.032 / 0.034 | Metric(Cur/Avg): 0 / 0.0\rTrain Step 4/5 | Loss(Cur/Avg): 0.044 / 0.036 | Metric(Cur/Avg): 0 / 0.0\rTrain Step 5/5 | Loss(Cur/Avg): 0.044 / 0.038 | Metric(Cur/Avg): 0 / 0.0\rValid Step 1/2 | Loss(Cur/Avg): 0.029 / 0.029 | Metric(Cur/Avg): 0 / 0.0\rValid Step 2/2 | Loss(Cur/Avg): 0.016 / 0.023 | Metric(Cur/Avg): 0 / 0.0\rEpoch: 7 | LR: 1.0E-01 | train_loss: 0.038 | valid_loss: 0.023 \n",
            "----------------------------------------------------------------------------------------------------\n",
            "\rTrain Step 1/5 | Loss(Cur/Avg): 0.032 / 0.032 | Metric(Cur/Avg): 0 / 0.0\rTrain Step 2/5 | Loss(Cur/Avg): 0.041 / 0.037 | Metric(Cur/Avg): 0 / 0.0\rTrain Step 3/5 | Loss(Cur/Avg): 0.033 / 0.035 | Metric(Cur/Avg): 0 / 0.0\rTrain Step 4/5 | Loss(Cur/Avg): 0.033 / 0.035 | Metric(Cur/Avg): 0 / 0.0\rTrain Step 5/5 | Loss(Cur/Avg): 0.03 / 0.034 | Metric(Cur/Avg): 0 / 0.0\rValid Step 1/2 | Loss(Cur/Avg): 0.025 / 0.025 | Metric(Cur/Avg): 0 / 0.0\rValid Step 2/2 | Loss(Cur/Avg): 0.014 / 0.019 | Metric(Cur/Avg): 0 / 0.0\rEpoch: 8 | LR: 1.0E-01 | train_loss: 0.034 | valid_loss: 0.019 \n",
            "----------------------------------------------------------------------------------------------------\n",
            "\rTrain Step 1/5 | Loss(Cur/Avg): 0.027 / 0.027 | Metric(Cur/Avg): 0 / 0.0\rTrain Step 2/5 | Loss(Cur/Avg): 0.033 / 0.03 | Metric(Cur/Avg): 0 / 0.0\rTrain Step 3/5 | Loss(Cur/Avg): 0.029 / 0.03 | Metric(Cur/Avg): 0 / 0.0\rTrain Step 4/5 | Loss(Cur/Avg): 0.024 / 0.028 | Metric(Cur/Avg): 0 / 0.0\rTrain Step 5/5 | Loss(Cur/Avg): 0.032 / 0.029 | Metric(Cur/Avg): 0 / 0.0\rValid Step 1/2 | Loss(Cur/Avg): 0.022 / 0.022 | Metric(Cur/Avg): 0 / 0.0\rValid Step 2/2 | Loss(Cur/Avg): 0.012 / 0.017 | Metric(Cur/Avg): 0 / 0.0\rEpoch: 9 | LR: 1.0E-01 | train_loss: 0.029 | valid_loss: 0.017 \n",
            "----------------------------------------------------------------------------------------------------\n",
            "Epoch: 10 | LR: 1.0E-01 | train_loss: 0.025 | valid_loss: 0.015 \n",
            "----------------------------------------------------------------------------------------------------\n",
            "Epoch: 11 | LR: 1.0E-01 | train_loss: 0.022 | valid_loss: 0.012 \n",
            "----------------------------------------------------------------------------------------------------\n",
            "Epoch: 12 | LR: 1.0E-01 | train_loss: 0.019 | valid_loss: 0.011 \n",
            "----------------------------------------------------------------------------------------------------\n",
            "Epoch: 13 | LR: 1.0E-01 | train_loss: 0.017 | valid_loss: 0.009 \n",
            "----------------------------------------------------------------------------------------------------\n",
            "Epoch: 14 | LR: 1.0E-01 | train_loss: 0.015 | valid_loss: 0.008 \n",
            "----------------------------------------------------------------------------------------------------\n",
            "Epoch: 15 | LR: 1.0E-01 | train_loss: 0.013 | valid_loss: 0.007 \n",
            "----------------------------------------------------------------------------------------------------\n",
            "Epoch: 16 | LR: 1.0E-01 | train_loss: 0.011 | valid_loss: 0.006 \n",
            "----------------------------------------------------------------------------------------------------\n",
            "Epoch: 17 | LR: 1.0E-01 | train_loss: 0.01 | valid_loss: 0.005 \n",
            "----------------------------------------------------------------------------------------------------\n",
            "Epoch: 18 | LR: 1.0E-01 | train_loss: 0.009 | valid_loss: 0.004 \n",
            "----------------------------------------------------------------------------------------------------\n",
            "Epoch: 19 | LR: 1.0E-01 | train_loss: 0.008 | valid_loss: 0.004 \n",
            "----------------------------------------------------------------------------------------------------\n",
            "Epoch: 20 | LR: 1.0E-01 | train_loss: 0.007 | valid_loss: 0.003 \n",
            "----------------------------------------------------------------------------------------------------\n",
            "Epoch: 21 | LR: 1.0E-01 | train_loss: 0.006 | valid_loss: 0.003 \n",
            "----------------------------------------------------------------------------------------------------\n",
            "Epoch: 22 | LR: 1.0E-01 | train_loss: 0.005 | valid_loss: 0.002 \n",
            "----------------------------------------------------------------------------------------------------\n",
            "Epoch: 23 | LR: 1.0E-01 | train_loss: 0.005 | valid_loss: 0.002 \n",
            "----------------------------------------------------------------------------------------------------\n",
            "Epoch: 24 | LR: 1.0E-01 | train_loss: 0.004 | valid_loss: 0.002 \n",
            "----------------------------------------------------------------------------------------------------\n",
            "Epoch: 25 | LR: 1.0E-01 | train_loss: 0.004 | valid_loss: 0.002 \n",
            "----------------------------------------------------------------------------------------------------\n",
            "Epoch: 26 | LR: 1.0E-01 | train_loss: 0.003 | valid_loss: 0.001 \n",
            "----------------------------------------------------------------------------------------------------\n",
            "Epoch: 27 | LR: 1.0E-01 | train_loss: 0.003 | valid_loss: 0.001 \n",
            "----------------------------------------------------------------------------------------------------\n",
            "Epoch: 28 | LR: 1.0E-01 | train_loss: 0.003 | valid_loss: 0.001 \n",
            "----------------------------------------------------------------------------------------------------\n",
            "Epoch: 29 | LR: 1.0E-01 | train_loss: 0.002 | valid_loss: 0.001 \n",
            "----------------------------------------------------------------------------------------------------\n",
            "Epoch: 30 | LR: 1.0E-01 | train_loss: 0.002 | valid_loss: 0.001 \n",
            "----------------------------------------------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "learner.model.state_dict()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M1lUYnGkddvp",
        "outputId": "a2d00d9a-a94d-4fcd-c4c8-a92c05be8bd1"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "OrderedDict([('0.weight', tensor([[0.4515]], device='cuda:0')),\n",
              "             ('0.bias', tensor([1.0251], device='cuda:0'))])"
            ]
          },
          "metadata": {},
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sstlearner.plot_loss_curve()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "oUdQkVNMdq5e",
        "outputId": "39511573-c155-4a6e-865b-9fe86e35a44d"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAi4AAAHHCAYAAACY6dMIAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAABLFElEQVR4nO3deXhU1eH/8c+dSWaykYQA2SSyCCIoBERJI2qxRAMqBVekVhYRfuLyrY1YpcqitqWCUtRSqQuibVnEiloXBNOCigiyFRdAsSgoSViUTBayzdzfH5OZZCBAJpklwffree4zd+49986ZyzxPPpx7zrmGaZqmAAAAWgFLuCsAAADQWAQXAADQahBcAABAq0FwAQAArQbBBQAAtBoEFwAA0GoQXAAAQKtBcAEAAK0GwQUAALQaBBcAANBqEFwABN3ChQtlGIY2btwY7qoAaOUILgAAoNUguAAAgFaD4AKgRdiyZYuGDh2q+Ph4xcXFafDgwfroo498ylRXV+vBBx9U9+7dFRUVpXbt2unCCy/UqlWrvGUKCws1btw4dezYUXa7XWlpaRo+fLi+/vrrEH8jAMEQEe4KAMBnn32miy66SPHx8frNb36jyMhI/fWvf9WgQYO0Zs0aZWVlSZJmzJihmTNn6pZbbtGAAQPkcDi0ceNGbd68WZdeeqkk6ZprrtFnn32mO++8U507d9b+/fu1atUq7dmzR507dw7jtwQQCIZpmma4KwHg1LZw4UKNGzdOH3/8sc4777xj9l911VV66623tH37dnXt2lWSVFBQoB49eqhfv35as2aNJKlv377q2LGj3njjjQY/5/Dhw2rbtq1mz56tyZMnB+8LAQgbbhUBCCun06mVK1dqxIgR3tAiSWlpafrFL36hDz74QA6HQ5KUmJiozz77TF9++WWD54qOjpbNZtPq1av1ww8/hKT+AEKL4AIgrA4cOKDy8nL16NHjmH09e/aUy+XS3r17JUkPPfSQDh8+rDPPPFO9e/fWPffco23btnnL2+12PfLII3r77beVkpKiiy++WLNmzVJhYWHIvg+A4CK4AGg1Lr74Yn311VdasGCBzjnnHD377LM699xz9eyzz3rL3HXXXfriiy80c+ZMRUVFaerUqerZs6e2bNkSxpoDCBSCC4Cw6tChg2JiYrRz585j9u3YsUMWi0UZGRnebUlJSRo3bpwWL16svXv3qk+fPpoxY4bPcWeccYbuvvturVy5Up9++qmqqqr02GOPBfurAAgBgguAsLJarbrsssv02muv+QxZLioq0qJFi3ThhRcqPj5eknTo0CGfY+Pi4tStWzdVVlZKksrLy1VRUeFT5owzzlCbNm28ZQC0bgyHBhAyCxYs0IoVK47ZPmPGDK1atUoXXnihbrvtNkVEROivf/2rKisrNWvWLG+5Xr16adCgQerfv7+SkpK0ceNGvfzyy7rjjjskSV988YUGDx6s66+/Xr169VJERISWL1+uoqIi3XDDDSH7ngCCh+HQAILOMxz6ePbu3asDBw5oypQpWrt2rVwul7KysvT73/9e2dnZ3nK///3v9frrr+uLL75QZWWlOnXqpJtuukn33HOPIiMjdejQIU2fPl35+fnau3evIiIidNZZZ+nuu+/WddddF4qvCiDICC4AAKDVoI8LAABoNQguAACg1SC4AACAVoPgAgAAWg2CCwAAaDUILgAAoNU4JSagc7lc2rdvn9q0aSPDMMJdHQAA0AimaaqkpETp6emyWBrXlnJKBJd9+/b5PMsEAAC0Hnv37lXHjh0bVfaUCC5t2rSR5P7inmeaAACAls3hcCgjI8P7d7wxTong4rk9FB8fT3ABAKCV8aebB51zAQBAq0FwAQAArQbBBQAAtBqnRB8XAMCpxel0qrq6OtzVQABERkbKarUG7HwEFwBAi2GapgoLC3X48OFwVwUBlJiYqNTU1IDMtUZwAQC0GJ7QkpycrJiYGCYVbeVM01R5ebn2798vSUpLS2v2OQkuAIAWwel0ekNLu3btwl0dBEh0dLQkaf/+/UpOTm72bSM65wIAWgRPn5aYmJgw1wSB5vk3DUS/JYILAKBF4fbQqSeQ/6YEFwAA0GoQXAAAaIE6d+6suXPnhrsaLQ7BBQCAZjAM44TLjBkzmnTejz/+WBMnTmxW3QYNGqS77rqrWedoaRhVdAIul6mDpZUqraxRl/ax3HcFAByjoKDAu7506VJNmzZNO3fu9G6Li4vzrpumKafTqYiIk//57dChQ2AreoqgxeUEyqudGvCHfP3ssTWqqHaFuzoAgBYoNTXVuyQkJMgwDO/7HTt2qE2bNnr77bfVv39/2e12ffDBB/rqq680fPhwpaSkKC4uTueff77effddn/MefavIMAw9++yzuuqqqxQTE6Pu3bvr9ddfb1bd//nPf+rss8+W3W5X586d9dhjj/ns/8tf/qLu3bsrKipKKSkpuvbaa737Xn75ZfXu3VvR0dFq166dcnJyVFZW1qz6NAYtLicQE1k31ry0skbRtsBNWQwAODnTNHWk2hmWz46OtAaspf2+++7To48+qq5du6pt27bau3evLr/8cv3+97+X3W7Xiy++qGHDhmnnzp06/fTTj3ueBx98ULNmzdLs2bP15JNP6sYbb9Q333yjpKQkv+u0adMmXX/99ZoxY4ZGjhypDz/8ULfddpvatWunsWPHauPGjfq///s//e1vf9MFF1yg77//Xu+//74kdyvTqFGjNGvWLF111VUqKSnR+++/L9M0m3yNGovgcgIWi6FYm1VlVU6VVdaoQxt7uKsEAD8qR6qd6jXtnbB89ucP5SrGFpg/kw899JAuvfRS7/ukpCRlZmZ63z/88MNavny5Xn/9dd1xxx3HPc/YsWM1atQoSdIf/vAHPfHEE9qwYYOGDBnid53mzJmjwYMHa+rUqZKkM888U59//rlmz56tsWPHas+ePYqNjdWVV16pNm3aqFOnTurXr58kd3CpqanR1VdfrU6dOkmSevfu7XcdmoJbRScRF+X+0ZZW1oS5JgCA1uq8887zeV9aWqrJkyerZ8+eSkxMVFxcnLZv3649e/ac8Dx9+vTxrsfGxio+Pt47nb6/tm/froEDB/psGzhwoL788ks5nU5deuml6tSpk7p27aqbbrpJ//jHP1ReXi5JyszM1ODBg9W7d29dd911euaZZ/TDDz80qR7+osXlJGLtEZIqVUZwAYCQi4606vOHcsP22YESGxvr837y5MlatWqVHn30UXXr1k3R0dG69tprVVVVdcLzREZG+rw3DEMuV3D6YLZp00abN2/W6tWrtXLlSk2bNk0zZszQxx9/rMTERK1atUoffvihVq5cqSeffFL333+/1q9fry5dugSlPh4El5OIs7svUVkVwQUAQs0wjIDdrmlJ1q5dq7Fjx+qqq66S5G6B+frrr0Nah549e2rt2rXH1OvMM8/0Pk8oIiJCOTk5ysnJ0fTp05WYmKh///vfuvrqq2UYhgYOHKiBAwdq2rRp6tSpk5YvX668vLyg1vvU+zUEWKzNc6soPJ3DAACnnu7du+uVV17RsGHDZBiGpk6dGrSWkwMHDmjr1q0+29LS0nT33Xfr/PPP18MPP6yRI0dq3bp1+vOf/6y//OUvkqQ33nhD//vf/3TxxRerbdu2euutt+RyudSjRw+tX79e+fn5uuyyy5ScnKz169frwIED6tmzZ1C+Q30El5OI9bS4cKsIABAgc+bM0c0336wLLrhA7du317333iuHwxGUz1q0aJEWLVrks+3hhx/WAw88oJdeeknTpk3Tww8/rLS0ND300EMaO3asJCkxMVGvvPKKZsyYoYqKCnXv3l2LFy/W2Wefre3bt+u9997T3Llz5XA41KlTJz322GMaOnRoUL5DfYYZirFLQeZwOJSQkKDi4mLFx8cH9Nx3LdmiV7fu0wNX9NQtF3UN6LkBAHUqKiq0e/dudenSRVFRUeGuDgLoeP+2Tfn7zaiik/C0uDCqCACA8CO4nEQct4oAAGgxCC4nUdfiQudcAADCjeByEnTOBQCg5SC4nESc3T2WneACAED4EVxOgs65AAC0HASXk4hl5lwAAFoMgstJ1I0qonMuAADhRnA5ibop/2lxAQAg3AguJ8E8LgCAUBg0aJDuuusu7/vOnTtr7ty5JzzGMAy9+uqrQa1XS0NwOYnY2lFF5VVOOV2t/ukIAIAAGzZsmIYMGdLgvvfff1+GYWjbtm1+n/fjjz/WxIkTm1W3sWPHasSIEc06R0tDcDkJT+dciQ66AIBjjR8/XqtWrdK33357zL7nn39e5513nvr06eP3eTt06KCYmJhAVPGUQnA5CXuERREWQxK3iwAAx7ryyivVoUMHLVy40Gd7aWmpli1bpvHjx+vQoUMaNWqUTjvtNMXExKh3795avHjxCc979K2iL7/8UhdffLGioqLUq1cvrVq1qtl1X7NmjQYMGCC73a60tDTdd999qqmp+1v38ssvq3fv3oqOjla7du2Uk5OjsrIySdLq1as1YMAAxcbGKjExUQMHDtQ333zT7DqdTMTJi/y4GYahWHuEio9UE1wAINRMU6ouD89nR8ZIhnHSYhERERo9erQWLlyo+++/X0btMcuWLZPT6dSoUaNUWlqq/v37695771V8fLzefPNN3XTTTTrjjDM0YMCAk36Gy+XS1VdfrZSUFK1fv17FxcU+/WGa4rvvvtPll1+usWPH6sUXX9SOHTs0YcIERUVFacaMGSooKNCoUaM0a9YsXXXVVSopKdH7778v0zRVU1OjESNGaMKECVq8eLGqqqq0YcMG73cPJoJLI8TVBheeVwQAIVZdLv0hPTyf/dt9ki22UUVvvvlmzZ49W2vWrNGgQYMkuW8TXXPNNUpISFBCQoImT57sLX/nnXfqnXfe0UsvvdSo4PLuu+9qx44deuedd5Se7r4ef/jDHzR06FD/v1etv/zlL8rIyNCf//xnGYahs846S/v27dO9996radOmqaCgQDU1Nbr66qvVqVMnSVLv3r0lSd9//72Ki4t15ZVX6owzzpAk9ezZs8l18Qe3ihohlmn/AQAncNZZZ+mCCy7QggULJEm7du3S+++/r/Hjx0uSnE6nHn74YfXu3VtJSUmKi4vTO++8oz179jTq/Nu3b1dGRoY3tEhSdnZ2s+q8fft2ZWdn+7SSDBw4UKWlpfr222+VmZmpwYMHq3fv3rruuuv0zDPP6IcffpAkJSUlaezYscrNzdWwYcP0+OOPq6CgoFn1aSxaXBqBaf8BIEwiY9wtH+H6bD+MHz9ed955p+bNm6fnn39eZ5xxhn76059KkmbPnq3HH39cc+fOVe/evRUbG6u77rpLVVVVwah5QFitVq1atUoffvihVq5cqSeffFL333+/1q9fry5duuj555/X//3f/2nFihVaunSpHnjgAa1atUo/+clPglovWlwagblcACBMDMN9uyYci5/9Na6//npZLBYtWrRIL774om6++WZva8batWs1fPhw/fKXv1RmZqa6du2qL774otHn7tmzp/bu3evTqvHRRx/5Vb+Gzrlu3TqZZt1UH2vXrlWbNm3UsWNHSe5+ngMHDtSDDz6oLVu2yGazafny5d7y/fr105QpU/Thhx/qnHPO0aJFi5pVp8agxaURCC4AgJOJi4vTyJEjNWXKFDkcDo0dO9a7r3v37nr55Zf14Ycfqm3btpozZ46KiorUq1evRp07JydHZ555psaMGaPZs2fL4XDo/vvvb9SxxcXF2rp1q8+2du3a6bbbbtPcuXN155136o477tDOnTs1ffp05eXlyWKxaP369crPz9dll12m5ORkrV+/XgcOHFDPnj21e/duPf300/r5z3+u9PR07dy5U19++aVGjx7d2MvVZASXRqi7VUTnXADA8Y0fP17PPfecLr/8cp/+KA888ID+97//KTc3VzExMZo4caJGjBih4uLiRp3XYrFo+fLlGj9+vAYMGKDOnTvriSeeOO7Ed/WtXr1a/fr1O6aezz77rN566y3dc889yszMVFJSksaPH68HHnhAkhQfH6/33ntPc+fOlcPhUKdOnfTYY49p6NChKioq0o4dO/TCCy/o0KFDSktL0+23367/9//+nx9Xq2kMs34bUSO89957mj17tjZt2qSCggItX778hLPyrV69Wpdccskx2wsKCpSamup9P2/ePM2ePVuFhYXKzMzUk08+2aie1pLkcDiUkJCg4uJixcfH+/N1GmXG659p4Ydf645Lumlybo+Anx8AIFVUVGj37t3q0qWLoqKiwl0dBNDx/m2b8vfb7z4uZWVlyszM1Lx58/w6bufOnSooKPAuycnJ3n1Lly5VXl6epk+frs2bNyszM1O5ubnav3+/v9ULCs+oIjrnAgAQXn7fKho6dGiTxo0nJycrMTGxwX1z5szRhAkTNG7cOEnS/Pnz9eabb2rBggW67777/P6sQIuljwsAAC1CyEYV9e3bV2lpabr00ku1du1a7/aqqipt2rRJOTk5dZWyWJSTk6N169Y1eK7Kyko5HA6fJZi8nXN5VhEAAGEV9OCSlpam+fPn65///Kf++c9/KiMjQ4MGDdLmzZslSQcPHpTT6VRKSorPcSkpKSosLGzwnDNnzvTORJiQkKCMjIygfodYG51zAQBoCYI+qqhHjx7q0aOuQ+sFF1ygr776Sn/605/0t7/9rUnnnDJlivLy8rzvHQ5HUMMLt4oAIHT8HDOCViCQ/6ZhGQ49YMAAffDBB5Kk9u3by2q1qqioyKdMUVGRz6ij+ux2u+x2e9Dr6cE8LgAQfJGRkZKk8vJyRUdHh7k2CKTycveDMj3/xs0RluCydetWpaWlSZJsNpv69++v/Px877Bql8ul/Px83XHHHeGo3jEYVQQAwWe1WpWYmOgdURoTExOSpw0jeEzTVHl5ufbv36/ExERZrdZmn9Pv4FJaWqpdu3Z53+/evVtbt25VUlKSTj/9dE2ZMkXfffedXnzxRUnS3Llz1aVLF5199tmqqKjQs88+q3//+99auXKl9xx5eXkaM2aMzjvvPA0YMEBz585VWVmZd5RRuNHiAgCh4WlpbynTYSAwEhMTj3sXxV9+B5eNGzf6TCjn6WsyZswYLVy4UAUFBT5Pu6yqqtLdd9+t7777TjExMerTp4/effddn3OMHDlSBw4c0LRp01RYWKi+fftqxYoVx3TYDZe6Pi50zgWAYDIMQ2lpaUpOTlZ1dXW4q4MAiIyMDEhLi4ffM+e2RMGeObf4SLUyH3S3EH3xu6GyRfBsSgAAmiskM+f+GMXa6pIit4sAAAgfgksjRFgtiop0Xyo66AIAED4El0aK8z4hmuACAEC4EFwaiUnoAAAIP4JLI9VN+09wAQAgXAgujRTHkGgAAMKO4NJIntlzuVUEAED4EFwaKZbOuQAAhB3BpZGY9h8AgPAjuDSSt8WliuACAEC4EFwaiRYXAADCj+DSSIwqAgAg/AgujUTnXAAAwo/g0kgMhwYAIPwILo1EHxcAAMKP4NJI3CoCACD8CC6NROdcAADCj+DSSDwdGgCA8CO4NJK3c25VjUzTDHNtAAD4cSK4NJLnVpHLlI5Uc7sIAIBwILg0UnSkVRbDvU4HXQAAwoPg0kiGYSjWRgddAADCieDiBzroAgAQXgQXP3g66HKrCACA8CC4+IHZcwEACC+Cix+YPRcAgPAiuPiB4AIAQHgRXPzArSIAAMKL4OKHus65DIcGACAcCC5+YDg0AADhRXDxQ5yN4AIAQDgRXPxA51wAAMKL4OIHOucCABBeBBc/1PVxoXMuAADhQHDxQ1wUt4oAAAgngosf4mqHQ5dVEVwAAAgHgosfGA4NAEB4EVz8EGvjVhEAAOFEcPGDZ1RRRbVLNU5XmGsDAMCPD8HFD55bRZJUVsXIIgAAQs3v4PLee+9p2LBhSk9Pl2EYevXVV09Y/pVXXtGll16qDh06KD4+XtnZ2XrnnXd8ysyYMUOGYfgsZ511lr9VCzpbhEU2q/uS0c8FAIDQ8zu4lJWVKTMzU/PmzWtU+ffee0+XXnqp3nrrLW3atEmXXHKJhg0bpi1btviUO/vss1VQUOBdPvjgA3+rFhKeBy0SXAAACL2IkxfxNXToUA0dOrTR5efOnevz/g9/+INee+01/etf/1K/fv3qKhIRodTUVH+rE3Kx9gj9UF5NB10AAMIg5H1cXC6XSkpKlJSU5LP9yy+/VHp6urp27aobb7xRe/bsOe45Kisr5XA4fJZQiWP2XAAAwibkweXRRx9VaWmprr/+eu+2rKwsLVy4UCtWrNBTTz2l3bt366KLLlJJSUmD55g5c6YSEhK8S0ZGRqiqz4MWAQAIo5AGl0WLFunBBx/USy+9pOTkZO/2oUOH6rrrrlOfPn2Um5urt956S4cPH9ZLL73U4HmmTJmi4uJi77J3795QfQUmoQMAIIz87uPSVEuWLNEtt9yiZcuWKScn54RlExMTdeaZZ2rXrl0N7rfb7bLb7cGo5kkx7T8AAOETkhaXxYsXa9y4cVq8eLGuuOKKk5YvLS3VV199pbS0tBDUzj/MngsAQPj43eJSWlrq0xKye/dubd26VUlJSTr99NM1ZcoUfffdd3rxxRcluW8PjRkzRo8//riysrJUWFgoSYqOjlZCQoIkafLkyRo2bJg6deqkffv2afr06bJarRo1alQgvmNAcasIAIDw8bvFZePGjerXr593KHNeXp769eunadOmSZIKCgp8RgQ9/fTTqqmp0e233660tDTv8qtf/cpb5ttvv9WoUaPUo0cPXX/99WrXrp0++ugjdejQobnfL+AYVQQAQPj43eIyaNAgmaZ53P0LFy70eb969eqTnnPJkiX+ViNsPC0uJRW0uAAAEGo8q8hPccycCwBA2BBc/OTt48KoIgAAQo7g4icmoAMAIHwILn6KY1QRAABhQ3DxUyyjigAACBuCi588nXO5VQQAQOgRXPwUZ4+U5L5VdKJh4QAAIPAILn6KrW1xqXGZqqxxhbk2AAD8uBBc/OR5VpFEB10AAEKN4OIni8VQjM0zCR0ddAEACCWCSxMwlwsAAOFBcGmCOGbPBQAgLAguTRDLkGgAAMKC4NIEng66dM4FACC0CC5NwLT/AACEB8GlCeo65zKqCACAUCK4NEEsLS4AAIQFwaUJPM8rIrgAABBaBJcmYB4XAADCg+DSBHTOBQAgPAguTUDnXAAAwoPg0gR0zgUAIDwILk3g7ZzLlP8AAIQUwaUJPDPnllYQXAAACCWCSxMwqggAgPAguDQBo4oAAAgPgksTeDvnVjnlcplhrg0AAD8eBJcm8LS4SFJ5NUOiAQAIFYJLE0RFWmQx3OvcLgIAIHQILk1gGAYddAEACAOCSxO1oYMuAAAhR3BpIlpcAAAIPYJLE9VN+0/nXAAAQoXg0kTM5QIAQOgRXJootvZ5RdwqAgAgdAguTcQTogEACD2CSxNxqwgAgNAjuDRR3agiOucCABAqBJcmosUFAIDQ8zu4vPfeexo2bJjS09NlGIZeffXVkx6zevVqnXvuubLb7erWrZsWLlx4TJl58+apc+fOioqKUlZWljZs2OBv1UIq1lbbObeK4AIAQKj4HVzKysqUmZmpefPmNar87t27dcUVV+iSSy7R1q1bddddd+mWW27RO++84y2zdOlS5eXlafr06dq8ebMyMzOVm5ur/fv3+1u9kKFzLgAAoRdx8iK+hg4dqqFDhza6/Pz589WlSxc99thjkqSePXvqgw8+0J/+9Cfl5uZKkubMmaMJEyZo3Lhx3mPefPNNLViwQPfdd5+/VQwJbhUBABB6Qe/jsm7dOuXk5Phsy83N1bp16yRJVVVV2rRpk08Zi8WinJwcb5mWiM65AACEnt8tLv4qLCxUSkqKz7aUlBQ5HA4dOXJEP/zwg5xOZ4NlduzY0eA5KysrVVlZ6X3vcDgCX/GT4FYRAACh1ypHFc2cOVMJCQneJSMjI+R14FYRAAChF/TgkpqaqqKiIp9tRUVFio+PV3R0tNq3by+r1dpgmdTU1AbPOWXKFBUXF3uXvXv3Bq3+x8OU/wAAhF7Qg0t2drby8/N9tq1atUrZ2dmSJJvNpv79+/uUcblcys/P95Y5mt1uV3x8vM8Sap4Wl8oal6qdrpB/PgAAP0Z+B5fS0lJt3bpVW7duleQe7rx161bt2bNHkrs1ZPTo0d7yt956q/73v//pN7/5jXbs2KG//OUveumll/TrX//aWyYvL0/PPPOMXnjhBW3fvl2TJk1SWVmZd5RRS+Tp4yJxuwgAgFDxu3Puxo0bdckll3jf5+XlSZLGjBmjhQsXqqCgwBtiJKlLly5688039etf/1qPP/64OnbsqGeffdY7FFqSRo4cqQMHDmjatGkqLCxU3759tWLFimM67LYkkVaLbBEWVdW4VFpZo8QYW7irBADAKc8wTdMMdyWay+FwKCEhQcXFxSG9bXTuw6v0fVmV3rnrYvVIbROyzwUA4FTQlL/frXJUUUtBB10AAEKL4NIMsTaGRAMAEEoEl2ZgLhcAAEKL4NIMddP+E1wAAAgFgkszxEXR4gIAQCgRXJohztPHpYoHLQIAEAoEl2bgVhEAAKFFcGmGuNrh0NwqAgAgNAguzUCLCwAAoUVwaYZYhkMDABBSBJdmqJvHhc65AACEAsGlGbhVBABAaBFcmiGWzrkAAIQUwaUZmPIfAIDQIrg0A7eKAAAILYJLM3hbXKqcMk0zzLUBAODUR3BpBk+Li9NlqrLGFebaAABw6iO4NENMpNW7zu0iAACCj+DSDBaLoVgbI4sAAAgVgksz0UEXAIDQIbg0E7PnAgAQOgSXZqprcakOc00AADj1EVyayTN7biktLgAABB3BpZmYPRcAgNAhuDRTLMEFAICQIbg0E6OKAAAIHYJLM3GrCACA0CG4NFOct8WFzrkAAAQbwaWZ6OMCAEDoEFyaKc7OlP8AAIQKwaWZ6JwLAEDoEFyayXurqIrgAgBAsBFcmolnFQEAEDoEl2aKtXGrCACAUCG4NBPzuAAAEDoEl2byPGSxvMopl8sMc20AADi1EVyaydM5V6KDLgAAwUZwaSZ7hEURFkMSHXQBAAg2gkszGYbBXC4AAIQIwSUA6KALAEBoNCm4zJs3T507d1ZUVJSysrK0YcOG45YdNGiQDMM4Zrniiiu8ZcaOHXvM/iFDhjSlamERy7T/AACERMTJi/haunSp8vLyNH/+fGVlZWnu3LnKzc3Vzp07lZycfEz5V155RVVVVd73hw4dUmZmpq677jqfckOGDNHzzz/vfW+32/2tWthwqwgAgNDwu8Vlzpw5mjBhgsaNG6devXpp/vz5iomJ0YIFCxosn5SUpNTUVO+yatUqxcTEHBNc7Ha7T7m2bds27RuFQRzT/gMAEBJ+BZeqqipt2rRJOTk5dSewWJSTk6N169Y16hzPPfecbrjhBsXGxvpsX716tZKTk9WjRw9NmjRJhw4dOu45Kisr5XA4fJZwqps9l1FFAAAEk1/B5eDBg3I6nUpJSfHZnpKSosLCwpMev2HDBn366ae65ZZbfLYPGTJEL774ovLz8/XII49ozZo1Gjp0qJzOhoPAzJkzlZCQ4F0yMjL8+RoB571VVEGLCwAAweR3H5fmeO6559S7d28NGDDAZ/sNN9zgXe/du7f69OmjM844Q6tXr9bgwYOPOc+UKVOUl5fnfe9wOMIaXuLonAsAQEj41eLSvn17Wa1WFRUV+WwvKipSamrqCY8tKyvTkiVLNH78+JN+TteuXdW+fXvt2rWrwf12u13x8fE+SzjRORcAgNDwK7jYbDb1799f+fn53m0ul0v5+fnKzs4+4bHLli1TZWWlfvnLX570c7799lsdOnRIaWlp/lQvbGKZxwUAgJDwe1RRXl6ennnmGb3wwgvavn27Jk2apLKyMo0bN06SNHr0aE2ZMuWY45577jmNGDFC7dq189leWlqqe+65Rx999JG+/vpr5efna/jw4erWrZtyc3Ob+LVCi1FFAACEht99XEaOHKkDBw5o2rRpKiwsVN++fbVixQpvh909e/bIYvHNQzt37tQHH3yglStXHnM+q9Wqbdu26YUXXtDhw4eVnp6uyy67TA8//HCrmcul7lYRo4oAAAgmwzRNM9yVaC6Hw6GEhAQVFxeHpb/Lik8LdOvfN6t/p7b656QLQv75AAC0Rk35+82zigIgzh4piT4uAAAEG8ElADzPKmJUEQAAwUVwCQCeDg0AQGgQXAKgbjg0nXMBAAgmgksAeIJLldOlqhpXmGsDAMCpi+ASALE2q3ed20UAAAQPwSUAIqwWRUW6LyUddAEACB6CS4Awey4AAMFHcAkQnlcEAEDwEVwCJNbGtP8AAAQbwSVAmMsFAIDgI7gECLPnAgAQfASXAKGPCwAAwUdwCRBuFQEAEHwElwDxtLjQORcAgOAhuAQIt4oAAAg+gkuAxNV2ziW4AAAQPASXAPG0uJQQXAAACBqCS4DQORcAgOAjuASIZ+ZcggsAAMFDcAmQulFFBBcAAIKF4BIgdbeKGA4NAECwEFwCJJZRRQAABB3BJUDiompbXKpqZJpmmGsDAMCpieASIJ5bRS5TOlLN7SIAAIKB4BIg0ZFWWQz3Oh10AQAIDoJLgBiGUW9INC0uAAAEA8ElgHheEQAAwUVwCSDPyCJuFQEAEBwElwBi2n8AAIKL4BJAzJ4LAEBwEVwCKJbZcwEACCqCSwBxqwgAgOAiuAQQnXMBAAgugksAMRwaAIDgIrgEUJyt7nlFAAAg8AguAVQ3qojOuQAABAPBJYDonAsAQHARXAKIeVwAAAgugksAeUYV0eICAEBwNCm4zJs3T507d1ZUVJSysrK0YcOG45ZduHChDMPwWaKionzKmKapadOmKS0tTdHR0crJydGXX37ZlKqFFbeKAAAILr+Dy9KlS5WXl6fp06dr8+bNyszMVG5urvbv33/cY+Lj41VQUOBdvvnmG5/9s2bN0hNPPKH58+dr/fr1io2NVW5urioqKvz/RmHErSIAAILL7+AyZ84cTZgwQePGjVOvXr00f/58xcTEaMGCBcc9xjAMpaamepeUlBTvPtM0NXfuXD3wwAMaPny4+vTpoxdffFH79u3Tq6++2qQvFS5xBBcAAILKr+BSVVWlTZs2KScnp+4EFotycnK0bt264x5XWlqqTp06KSMjQ8OHD9dnn33m3bd7924VFhb6nDMhIUFZWVnHPWdlZaUcDofP0hJ4Wlwqql2qcbrCXBsAAE49fgWXgwcPyul0+rSYSFJKSooKCwsbPKZHjx5asGCBXnvtNf3973+Xy+XSBRdcoG+//VaSvMf5c86ZM2cqISHBu2RkZPjzNYLG0zlXksqqmMsFAIBAC/qoouzsbI0ePVp9+/bVT3/6U73yyivq0KGD/vrXvzb5nFOmTFFxcbF32bt3bwBr3HT2CKsirYYkOugCABAMfgWX9u3by2q1qqioyGd7UVGRUlNTG3WOyMhI9evXT7t27ZIk73H+nNNutys+Pt5naSl4XhEAAMHjV3Cx2Wzq37+/8vPzvdtcLpfy8/OVnZ3dqHM4nU598sknSktLkyR16dJFqampPud0OBxav359o8/ZktBBFwCA4Inw94C8vDyNGTNG5513ngYMGKC5c+eqrKxM48aNkySNHj1ap512mmbOnClJeuihh/STn/xE3bp10+HDhzV79mx98803uuWWWyS5Rxzddddd+t3vfqfu3burS5cumjp1qtLT0zVixIjAfdMQqZvLhT4uAAAEmt/BZeTIkTpw4ICmTZumwsJC9e3bVytWrPB2rt2zZ48slrqGnB9++EETJkxQYWGh2rZtq/79++vDDz9Ur169vGV+85vfqKysTBMnTtThw4d14YUXasWKFcdMVNcaMJcLAADBY5imaYa7Es3lcDiUkJCg4uLisPd3Gb1gg9774oAeuy5T1/TvGNa6AADQkjXl7zfPKgqwOM/ziqpocQEAINAILgEWa+NWEQAAwUJwCTCGQwMAEDwElwBjVBEAAMFDcAkwRhUBABA8BJcA83bOJbgAABBwBJcAo8UFAIDgIbgEGJ1zAQAIHoJLgNE5FwCA4CG4BBi3igAACB6CS4Axcy4AAMFDcAkw+rgAABA8BJcA8wSXaqepyhr6uQAAEEgElwDzPKtIooMuAACBRnAJMKvFUHSku59LaQW3iwAACCSCSxAwsggAgOAguAQBI4sAAAgOgksQ0OICAEBwEFyCgCHRAAAEB8ElCOIILgAABAXBJQjivLeKGA4NAEAgEVyCgFtFAAAEB8ElCLyjigguAAAEFMElCBhVBABAcBBcgoDOuQAABAfBJQhi6ZwLAEBQEFyCgM65AAAEB8ElCJjyHwCA4CC4BEGsjc65AAAEA8ElCLhVBABAcBBcgqBuVBGdcwEACCSCSxB4W1yqamSaZphrAwDAqYPgEgSeFhfTlMqraHUBACBQCC5BEBVpkcVwr9PPBQCAwCG4BIFhGEz7DwBAEBBcgoQOugAABB7BJUhocQEAIPAILkHCXC4AAAQewSVIPNP+0+ICAEDgNCm4zJs3T507d1ZUVJSysrK0YcOG45Z95plndNFFF6lt27Zq27atcnJyjik/duxYGYbhswwZMqQpVWsxmPYfAIDA8zu4LF26VHl5eZo+fbo2b96szMxM5ebmav/+/Q2WX716tUaNGqX//Oc/WrdunTIyMnTZZZfpu+++8yk3ZMgQFRQUeJfFixc37RsFWmWJ9M06vw+L41YRAAAB53dwmTNnjiZMmKBx48apV69emj9/vmJiYrRgwYIGy//jH//Qbbfdpr59++qss87Ss88+K5fLpfz8fJ9ydrtdqamp3qVt27ZN+0aBdOAL6dEzpUXXS1Xlfh1KHxcAAALPr+BSVVWlTZs2KScnp+4EFotycnK0bl3jWiXKy8tVXV2tpKQkn+2rV69WcnKyevTooUmTJunQoUPHPUdlZaUcDofPEhTtukmx7aVKh7T9X34dWjeqiOHQAAAEil/B5eDBg3I6nUpJSfHZnpKSosLCwkad495771V6erpP+BkyZIhefPFF5efn65FHHtGaNWs0dOhQOZ0N/9GfOXOmEhISvEtGRoY/X6PxLBap7y/d61v+5tehbaJocQEAINBCOqroj3/8o5YsWaLly5crKirKu/2GG27Qz3/+c/Xu3VsjRozQG2+8oY8//lirV69u8DxTpkxRcXGxd9m7d2/wKt33F5IM6ev3pe//1+jDYm21o4qqCC4AAASKX8Glffv2slqtKioq8tleVFSk1NTUEx776KOP6o9//KNWrlypPn36nLBs165d1b59e+3atavB/Xa7XfHx8T5L0CRmSGf8zL2+5R+NPow+LgAABJ5fwcVms6l///4+HWs9HW2zs7OPe9ysWbP08MMPa8WKFTrvvPNO+jnffvutDh06pLS0NH+qFzz9am8XbV0kuRrXZ4VRRQAABJ7ft4ry8vL0zDPP6IUXXtD27ds1adIklZWVady4cZKk0aNHa8qUKd7yjzzyiKZOnaoFCxaoc+fOKiwsVGFhoUpLSyVJpaWluueee/TRRx/p66+/Vn5+voYPH65u3bopNzc3QF+zmc66QopuK5Xsk776d6MOoXMuAACB53dwGTlypB599FFNmzZNffv21datW7VixQpvh909e/aooKDAW/6pp55SVVWVrr32WqWlpXmXRx99VJJktVq1bds2/fznP9eZZ56p8ePHq3///nr//fdlt9sD9DWbKcIu9RnpXt/8YqMO4VYRAACBZ5imaYa7Es3lcDiUkJCg4uLi4PV3KfxEmn+hZImU7t7hHiZ9AjsLS5Q79z21i7Vp09RLg1MnAABasab8/eZZRY2V2ltK6yu5qqVtS09aPJZnFQEAEHAEF3+ce5P7dfPfpJM0VHk651bWuFTjdAW7ZgAA/CgQXPxxzrVSRJR0YLv03eYTFvX0cZGkMjroAgAQEAQXf0QnSj1/7l4/yUy6kVaLbBHuy8skdAAABAbBxV+e20Wf/vOkD15kLhcAAAKL4OKvThdKiZ1qH7z4+gmL0kEXAIDAIrj4y2KR+tXrpHsCsTZaXAAACCSCS1P0HSXJkL75QDr01XGLcasIAIDAIrg0RUJHqdtg9/rW4z94kWn/AQAILIJLUzXiwYu0uAAAEFgEl6bqcbkUnSSVFEi78hssQudcAAACi+DSVBF2KfMG9/qWhh+8yIMWAQAILIJLc3huF+18Wyo7eMxuz62i/SWVoawVAACnLIJLc6ScLaWfK7lqpP8uOWZ3rzT3ky7/uflbvbb1u1DXDgCAUw7Bpbk8rS5bjn3w4pBzUjUmu5NMU7r7pf/qPzv3h6GCAACcOgguzdXb8+DFHdJ3m3x2GYah6cPO1s8z01XjMjXp75u06Zvvw1RRAABaP4JLc0UlSL2Gu9cbePCixWLoseszNahHB1VUuzTu+Y+1vcAR4koCAHBqILgEgucRAJ/8U6oqO2Z3pNWip27sr/M6tZWjokajF2zQN4eOLQcAAE6M4BIInQZKbTtLVSXS5w0/eDHaZtVzY8/XWaltdKCkUjc9t0H7HRWhrScAAK0cwSUQLBbfTrrHkRAdqRdvHqDTk2K05/tyjV6wQcXl1SGqJAAArR/BJVAyfyEZFumbtSd88GJyfJT+Pj5LHdrYtaOwRDe/8LHKq5igDgCAxiC4BErCadIZtQ9e3PL3ExY9vV2M/jZ+gOKjIrTpmx806e+bVVXjCkElAQBo3QgugXRubSfdrYsk54lbUc5Kjdfz485XVKRFa744oMnL/iuXyzzhMQAA/NgRXALpzKFSTDuptFD6quEHL9bXv1OS5v+yvyIshl7/7z5Nf/0zmSbhBQCA4yG4BFKETepT++DFzQ0/ePFog3oka87IvjIM6W8ffaM/vftlECsIAEDrRnAJNM/ooi9WSKUHGnXIzzPT9dDwcyRJT+R/qefX7g5W7QAAaNUILoGW0ks6rb/7wYvbjn3w4vHc9JNOuvvSMyVJD/7rc72y+dtg1RAAgFaL4BIM3jld/n7MgxdP5I6fddO4gZ0lSfe8vE3vfl4UhMoBANB6EVyC4ZxrpIho94MXv93Y6MMMw9DUK3rp6n6nyekydfuizVr/v0NBrCgAAK1LRLgrcEqKSpDOHiH9d7F7Jt2M8xt9qMVi6JFr+8hRUa13t+/XyKc/Ump8lLqnxOnMlDbqnhyn7ilt1D0lTvFRkcH7DgAAtECGeQqMv3U4HEpISFBxcbHi4+PDXR23rz+QFl4h2dpIk3dKtli/Dq+oduqORZv17vb9xy2TlhClbsnuQHNmijvQdEsm0AAAWoem/P0muASLaUpPnit9/z/p7Kuls66QMgZICRmSYTT6NMXl1dp1oERfFJXqi6IS7drvfi1yVB73mLSEKHerTHKc0hKi1KGNXe3jPItNbWNsslgaXwcAAIKB4NKSgoskrX1cWjXNd1tcqtTxPHeI6Xi+lN5Pioz2+9RNCTQeVouhpFib2sXa6oUaW124aVP3vm2MTbYIukIBAAKP4NLSgouzWtr+L2nPOunbj6XCT9zDpOuzREipvd0hpuMAd3+YxE5+tcrUVz/Q7Npfqv0llTpYUqmDpe7lhyY8jbpNVISSYm3esJMUa1Nb77pdSbGRSoq1e/fF2Kwymlh/AMCPB8GlpQWXo1WVSwX/lb7dIO3d4A4zpQ0MeY5NdgeZjPOllHOk2PZSTHv34wRsMc2qQrXTpe/LqnTAG2aq3K9Hvy+t1PdlVWrK45NsERZviKm/tDsm8Li3J0ZHcusKAH6ECC4tPbgczTSl4r3uALP3Y3egKdgmuU7QKhIZ4w4wMUl1YSamnRTbrm7dsz22vXuEk7VpnXVdLlPFR6p1qKxK3/sslTpUVqUfyqq8+zzrlU14yrXFkNrG+LbkJMbY1CYqQrG2CMVFRSjOblWsPUKx9gi1qX2Nq/fK7SwAaH0ILq0tuDSkuqK2VaY2yBz6Sio/5F6cVU07Z0S0FBUv2eMbeE04zvaj9kfYTvoxpmmqvMqp72tDzA9HvX5fVqnvy6prX92Bx1Fx4qdoN5bNalFsbbiJs0coPipS8dERio+OrF2PVEJ0pOKjIuqtu8skREcq1hZBqw8AhBjB5VQILsdjmlJVqVR2UCr/Xio/WBdoyjzr9baXHZQqDgfu86322jDTxh1k7G1qQ0399/G++2xx7mHgtti69cgYyVLXOlLtdDUQcKr0Q3mVyiprVFrpVFlljcoqa1RS++rZXlpZrYpq/1t4GmIxpDZR7kDjaemJsVsVY7MqOjJCsXarom1W93abVTHe19r12rIxke71WFuEoiIt9PUBgBNoyt9vJqBrLQyjNiS0kZK6NO4YZ41U6XAvFQ29FrtfK4qPX6a6rPZclVLZAffSXJG1YcYep0hbrJJtcUo+OuDYYqW4GKlttDvsRMa4R1/ZYt2vkfFSZIxqrNEqN20qc9lU6opUSZXLHXIqauQ4Uq3iI9VyVFTLcaSm3rpnu3tbVY1LLlMqrt0eKIYhxURaFWOvCzuxtnoBqDbsxNoivNuibVZFR1oVFWlVVKTF+2qPOHqbVVERFkVYuUUG4MeF4HIqs0bU9oVJavo5nDVSVYlUWVIbaEpqw1BJbeApOWqboy4sVZXVW0ols7Z1pLrMvZQdf3K9xoqQFF+7uDdEuYNNRLQUGXXsa3SUFB/tU6bGYleFbDpi2lTuilSZK0IVZoSOuCJ0xGlVucuqMqdVpTURKnVaVFpjUUmNVSXVFjmqLSqusshRLZVVmSqrqvG2ApmmVFblVFmVs9nf87jf32IcFW7cr7YIi+wRFtkjre7XiKO3u9/b65ezWrz7bZ7Fu83qu8/qPofNSngCEFpNCi7z5s3T7NmzVVhYqMzMTD355JMaMGDAccsvW7ZMU6dO1ddff63u3bvrkUce0eWXX+7db5qmpk+frmeeeUaHDx/WwIED9dRTT6l79+5NqR4CyRohRbd1L81hmlL1kboQUz/QHG+9+ohUXe5eqsp933vWq8qlmiN1n1NT4V70Q6OrFiEprnZpFkukFG2XGWeTaXUvTotdTotNTiNSNZZI1Rg2VSlS1YpUpSJVaUaqUlZVuCJ1pDYsVbistYtFR5xWHXFZdcRpqNxpVZnTonKnRdWKULVZu1RZVV0VoWpFqEpWlZsRqpFV1bLWvrrfO2WRFPhbVxZD9UKOVTarocgIiyKt7sVmNWSr9z7SapEtwpDN87722AiLIavVUKTFIqvFUKTVkNViqX01FFFbJsJiKMJqKMJS+96z3bPNWlumdt1zngiLoUhr/XO730dY3Ovc1gNaB7+Dy9KlS5WXl6f58+crKytLc+fOVW5urnbu3Knk5ORjyn/44YcaNWqUZs6cqSuvvFKLFi3SiBEjtHnzZp1zzjmSpFmzZumJJ57QCy+8oC5dumjq1KnKzc3V559/rqioqOZ/S4SfYbiHcttiJHUI7LldLndYqR9yao64Ozqf9LXCHYKOfnVWSTWV7ltkNVUNvx7dWdpVLVVVy1BdPLAG9pu6T9iMkzqNCDmNCLmMCDkVIadhVY0i5JRFNbUBp0buYFRjWlRjWlQlq6pNi6pNi6pMq6pdFm8Zp2lxhyLTouqaCLlq3Puctedxmu7A5H1f++qSxRumjphWldbuc8oilwzvMe5Xd3mnafG+926rPY/Lu82Qy6zb7zmXz/565zDrPWf22PBTPxAdG5Dqhx+rxZDV8AQsd1CyGvIGJktt4LLWe/WsW2qPtXi2e9YN97PLLMZR2y06dpthyFJvu8Wod5zF/QBXT/0MQz7Husu6jzWMunN41r37j1PWs43gh1Dxu3NuVlaWzj//fP35z3+WJLlcLmVkZOjOO+/Ufffdd0z5kSNHqqysTG+88YZ3209+8hP17dtX8+fPl2maSk9P1913363JkydLkoqLi5WSkqKFCxfqhhtuOGmdfhSdc9HymGa9gNNQ0Kn03VZTcVT5iqPW6wUiZ3XtUtXAawPrrmrf4040pB4+nKbhDTHuYOMON6Z33fe9JwiZ5vH3H32uY17Nhj7Hvd+sXTzHm/W2+2wz67aZkkxZZEq153S/6qj3vuXqPqv+ds/3anCf6u+TVH/dcEd206ht2TMkQxb39tp9Ru2rZ5tRb92UUVvMUntmi8zaQGTI97j6xxqGUfs/BaP289znsNRuU73PNLzHSoZh8R7nOZ/h+R7e88unzp5zmvX2ez7Z9xj3NTN86iDvfkvtd1Rt+FO97+6pg7uOhrue3modfS7PuudzjgqQ3v2eutRt9jne+7me6+25bIbnk2RYLIqwWHTlxce/u9IUQe+cW1VVpU2bNmnKlCnebRaLRTk5OVq3bl2Dx6xbt055eXk+23Jzc/Xqq69Kknbv3q3CwkLl5OR49yckJCgrK0vr1q1rMLhUVlaqsrJuanuHw+HP1wACwzCkCLt7aWlMU3I5awNNtXvGZldNvZBTU29fvfeeci6n73Gec3nPU1NvX3VdedNZu81Vb3/t8d599c/prHcOV20ZZ91r/fXjbqv9PPOo401XXb+qE7AapqxySvKzLxINDP4zj3pFq1JpRkoXHwx3NfwLLgcPHpTT6VRKSorP9pSUFO3YsaPBYwoLCxssX1hY6N3v2Xa8MkebOXOmHnzwQX+qDvy4GIa7f5I1oknPwjplmKY7vNQPM97AUy/seEKOZ3E5645tcHH6nlv1P+c4xzS0z3vsUZ/lOZ959OvR+z37zAa2NXAe72eZdd9Bpu9rvXJm7XvTs67aV5dTLplyT61t1u03XbWncnrL152n3vH1znf0dp9jZNaGHJf31X2PoH7Zo9+bMuVuCzLN2vago/ZJpox65bz7Pb+Zuh+Qzz6jfrn6n13LMOvt8766yxmqf976n1PXdnW8fXWf73OCo46rq6P7e52orG+9G6yf5zvV2+60NG0y00BrlaOKpkyZ4tOK43A4lJGREcYaAWiRDEMyrJIl4L2NfhSMo17x43byaUhDw69xjO3bt5fValVRke/zdYqKipSamtrgMampqScs73n155x2u13x8fE+CwAAOPX5FVxsNpv69++v/Px87zaXy6X8/HxlZ2c3eEx2drZPeUlatWqVt3yXLl2UmprqU8bhcGj9+vXHPScAAPhx8vtWUV5ensaMGaPzzjtPAwYM0Ny5c1VWVqZx48ZJkkaPHq3TTjtNM2fOlCT96le/0k9/+lM99thjuuKKK7RkyRJt3LhRTz/9tCR3D+a77rpLv/vd79S9e3fvcOj09HSNGDEicN8UAAC0en4Hl5EjR+rAgQOaNm2aCgsL1bdvX61YscLbuXbPnj2y1HsWzQUXXKBFixbpgQce0G9/+1t1795dr776qncOF0n6zW9+o7KyMk2cOFGHDx/WhRdeqBUrVjCHCwAA8MFDFgEAQFg05e83DxkBAACtBsEFAAC0GgQXAADQahBcAABAq0FwAQAArQbBBQAAtBoEFwAA0GoQXAAAQKtBcAEAAK2G31P+t0SeyX8dDkeYawIAABrL83fbn0n8T4ngUlJSIknKyMgIc00AAIC/SkpKlJCQ0Kiyp8Szilwul/bt26c2bdrIMIyAntvhcCgjI0N79+7lOUh+4Lo1DdfNf1yzpuG6NQ3XzX8numamaaqkpETp6ek+D2g+kVOixcVisahjx45B/Yz4+Hh+pE3AdWsarpv/uGZNw3VrGq6b/453zRrb0uJB51wAANBqEFwAAECrQXA5CbvdrunTp8tut4e7Kq0K161puG7+45o1Ddetabhu/gv0NTslOucCAIAfB1pcAABAq0FwAQAArQbBBQAAtBoEFwAA0GoQXE5i3rx56ty5s6KiopSVlaUNGzaEu0ot1owZM2QYhs9y1llnhbtaLc57772nYcOGKT09XYZh6NVXX/XZb5qmpk2bprS0NEVHRysnJ0dffvlleCrbgpzsuo0dO/aY39+QIUPCU9kWYubMmTr//PPVpk0bJScna8SIEdq5c6dPmYqKCt1+++1q166d4uLidM0116ioqChMNW4ZGnPdBg0adMzv7dZbbw1TjVuGp556Sn369PFONJedna23337buz9QvzWCywksXbpUeXl5mj59ujZv3qzMzEzl5uZq//794a5ai3X22WeroKDAu3zwwQfhrlKLU1ZWpszMTM2bN6/B/bNmzdITTzyh+fPna/369YqNjVVubq4qKipCXNOW5WTXTZKGDBni8/tbvHhxCGvY8qxZs0a33367PvroI61atUrV1dW67LLLVFZW5i3z61//Wv/617+0bNkyrVmzRvv27dPVV18dxlqHX2OumyRNmDDB5/c2a9asMNW4ZejYsaP++Mc/atOmTdq4caN+9rOfafjw4frss88kBfC3ZuK4BgwYYN5+++3e906n00xPTzdnzpwZxlq1XNOnTzczMzPDXY1WRZK5fPly73uXy2Wmpqaas2fP9m47fPiwabfbzcWLF4ehhi3T0dfNNE1zzJgx5vDhw8NSn9Zi//79piRzzZo1pmm6f1uRkZHmsmXLvGW2b99uSjLXrVsXrmq2OEdfN9M0zZ/+9Kfmr371q/BVqpVo27at+eyzzwb0t0aLy3FUVVVp06ZNysnJ8W6zWCzKycnRunXrwlizlu3LL79Uenq6unbtqhtvvFF79uwJd5Vald27d6uwsNDnd5eQkKCsrCx+d42wevVqJScnq0ePHpo0aZIOHToU7iq1KMXFxZKkpKQkSdKmTZtUXV3t83s766yzdPrpp/N7q+fo6+bxj3/8Q+3bt9c555yjKVOmqLy8PBzVa5GcTqeWLFmisrIyZWdnB/S3dko8ZDEYDh48KKfTqZSUFJ/tKSkp2rFjR5hq1bJlZWVp4cKF6tGjhwoKCvTggw/qoosu0qeffqo2bdqEu3qtQmFhoSQ1+Lvz7EPDhgwZoquvvlpdunTRV199pd/+9rcaOnSo1q1bJ6vVGu7qhZ3L5dJdd92lgQMH6pxzzpHk/r3ZbDYlJib6lOX3Vqeh6yZJv/jFL9SpUyelp6dr27Ztuvfee7Vz50698sorYaxt+H3yySfKzs5WRUWF4uLitHz5cvXq1Utbt24N2G+N4IKAGTp0qHe9T58+ysrKUqdOnfTSSy9p/PjxYawZfgxuuOEG73rv3r3Vp08fnXHGGVq9erUGDx4cxpq1DLfffrs+/fRT+p356XjXbeLEid713r17Ky0tTYMHD9ZXX32lM844I9TVbDF69OihrVu3qri4WC+//LLGjBmjNWvWBPQzuFV0HO3bt5fVaj2mx3NRUZFSU1PDVKvWJTExUWeeeaZ27doV7qq0Gp7fFr+75uvatavat2/P70/SHXfcoTfeeEP/+c9/1LFjR+/21NRUVVVV6fDhwz7l+b25He+6NSQrK0uSfvS/N5vNpm7duql///6aOXOmMjMz9fjjjwf0t0ZwOQ6bzab+/fsrPz/fu83lcik/P1/Z2dlhrFnrUVpaqq+++kppaWnhrkqr0aVLF6Wmpvr87hwOh9avX8/vzk/ffvutDh069KP+/ZmmqTvuuEPLly/Xv//9b3Xp0sVnf//+/RUZGenze9u5c6f27Nnzo/69ney6NWTr1q2S9KP+vTXE5XKpsrIysL+1wPYfPrUsWbLEtNvt5sKFC83PP//cnDhxopmYmGgWFhaGu2ot0t13322uXr3a3L17t7l27VozJyfHbN++vbl///5wV61FKSkpMbds2WJu2bLFlGTOmTPH3LJli/nNN9+Ypmmaf/zjH83ExETztddeM7dt22YOHz7c7NKli3nkyJEw1zy8TnTdSkpKzMmTJ5vr1q0zd+/ebb777rvmueeea3bv3t2sqKgId9XDZtKkSWZCQoK5evVqs6CgwLuUl5d7y9x6663m6aefbv773/82N27caGZnZ5vZ2dlhrHX4ney67dq1y3zooYfMjRs3mrt37zZfe+01s2vXrubFF18c5pqH13333WeuWbPG3L17t7lt2zbzvvvuMw3DMFeuXGmaZuB+awSXk3jyySfN008/3bTZbOaAAQPMjz76KNxVarFGjhxppqWlmTabzTzttNPMkSNHmrt27Qp3tVqc//znP6akY5YxY8aYpukeEj116lQzJSXFtNvt5uDBg82dO3eGt9ItwImuW3l5uXnZZZeZHTp0MCMjI81OnTqZEyZM+NH/J6Oh6yXJfP75571ljhw5Yt52221m27ZtzZiYGPOqq64yCwoKwlfpFuBk123Pnj3mxRdfbCYlJZl2u93s1q2bec8995jFxcXhrXiY3XzzzWanTp1Mm81mdujQwRw8eLA3tJhm4H5rhmmaZhNbgAAAAEKKPi4AAKDVILgAAIBWg+ACAABaDYILAABoNQguAACg1SC4AACAVoPgAgAAWg2CC4BThmEYevXVV8NdDQBBRHABEBBjx46VYRjHLEOGDAl31QCcQiLCXQEAp44hQ4bo+eef99lmt9vDVBsApyJaXAAEjN1uV2pqqs/Stm1bSe7bOE899ZSGDh2q6Ohode3aVS+//LLP8Z988ol+9rOfKTo6Wu3atdPEiRNVWlrqU2bBggU6++yzZbfblZaWpjvuuMNn/8GDB3XVVVcpJiZG3bt31+uvv+7d98MPP+jGG29Uhw4dFB0dre7dux8TtAC0bAQXACEzdepUXXPNNfrvf/+rG2+8UTfccIO2b98uSSorK1Nubq7atm2rjz/+WMuWLdO7777rE0yeeuop3X777Zo4caI++eQTvf766+rWrZvPZzz44IO6/vrrtW3bNl1++eW68cYb9f3333s///PPP9fbb7+t7du366mnnlL79u1DdwEANF/gngsJ4MdszJgxptVqNWNjY32W3//+96Zpup+4e+utt/ock5WVZU6aNMk0TdN8+umnzbZt25qlpaXe/W+++aZpsVi8T3lOT08377///uPWQZL5wAMPeN+Xlpaaksy3337bNE3THDZsmDlu3LjAfGEAYUEfFwABc8kll+ipp57y2ZaUlORdz87O9tmXnZ2trVu3SpK2b9+uzMxMxcbGevcPHDhQLpdLO3fulGEY2rdvnwYPHnzCOvTp08e7Hhsbq/j4eO3fv1+SNGnSJF1zzTXavHmzLrvsMo0YMUIXXHBBk74rgPAguAAImNjY2GNu3QRKdHR0o8pFRkb6vDcMQy6XS5I0dOhQffPNN3rrrbe0atUqDR48WLfffrseffTRgNcXQHDQxwVAyHz00UfHvO/Zs6ckqWfPnvrvf/+rsrIy7/61a9fKYrGoR48eatOmjTp37qz8/Pxm1aFDhw4aM2aM/v73v2vu3Ll6+umnm3U+AKFFiwuAgKmsrFRhYaHPtoiICG8H2GXLlum8887ThRdeqH/84x/asGGDnnvuOUnSjTfeqOnTp2vMmDGaMWOGDhw4oDvvvFM33XSTUlJSJEkzZszQrbfequTkZA0dOlQlJSVau3at7rzzzkbVb9q0aerfv7/OPvtsVVZW6o033vAGJwCtA8EFQMCsWLFCaWlpPtt69OihHTt2SHKP+FmyZIluu+02paWlafHixerVq5ckKSYmRu+8845+9atf6fzzz1dMTIyuueYazZkzx3uuMWPGqKKiQn/60580efJktW/fXtdee22j62ez2TRlyhR9/fXXio6O1kUXXaQlS5YE4JsDCBXDNE0z3JUAcOozDEPLly/XiBEjwl0VAK0YfVwAAECrQXABAACtBn1cAIQEd6UBBAItLgAAoNUguAAAgFaD4AIAAFoNggsAAGg1CC4AAKDVILgAAIBWg+ACAABaDYILAABoNQguAACg1fj/MqnSr21rzcMAAAAASUVORK5CYII=\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Notebook Summary\n",
        "\n",
        "1. We resolved the linear regression problem by using the typical PyTorch Workflow which involves:\n",
        "    * Usage of Dataset and DataLoader\n",
        "    * Defining a `loss_fn` to optimized using an `optimizer`\n",
        "    * Building `Learner` class to encapsulate training and validation process"
      ],
      "metadata": {
        "id": "8KV-_I3l8LhE"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "YXls_zKstQut"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}